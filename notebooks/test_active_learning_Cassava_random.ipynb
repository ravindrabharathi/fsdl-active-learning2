{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "test-active-learning-Cassava-random",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravindrabharathi/fsdl-active-learning2/blob/cassava-deepweeds/notebooks/test_active_learning_Cassava_random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoWvbjJa3e53",
        "outputId": "6f65c4e2-263f-40d3-89d2-54cb7559cd12"
      },
      "source": [
        "!git clone --single-branch --branch cassava-deepweeds https://github.com/ravindrabharathi/fsdl-active-learning2.git \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fsdl-active-learning2'...\n",
            "remote: Enumerating objects: 442, done.\u001b[K\n",
            "remote: Counting objects: 100% (442/442), done.\u001b[K\n",
            "remote: Compressing objects: 100% (308/308), done.\u001b[K\n",
            "remote: Total 442 (delta 274), reused 271 (delta 130), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (442/442), 1.18 MiB | 23.26 MiB/s, done.\n",
            "Resolving deltas: 100% (274/274), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVuDwtl8t_Ew",
        "outputId": "cd62b9c6-4ce0-4db6-aae5-4a6e75437484"
      },
      "source": [
        "%cd fsdl-active-learning2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fsdl-active-learning2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ4k36MGtb-K",
        "outputId": "88a63c92-17c7-44c6-ba14-f56cf672f99b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJTqhmEStdHd"
      },
      "source": [
        "!mkdir './data/cassava/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BRIry8pt4Gb"
      },
      "source": [
        "!cp '/gdrive/MyDrive/cassava-kaggle/train_images.zip' './data/cassava/'\n",
        "!cp '/gdrive/MyDrive/cassava-kaggle/train.csv' './data/cassava/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0Lj5k0Kkjs9"
      },
      "source": [
        "!unzip -q './data/cassava/train_images.zip' -d './data/cassava/images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds7QXOu5imsW"
      },
      "source": [
        "# alternative way: if you cloned the repository to your GDrive account, you can mount it here\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive', force_remount=True)\n",
        "#%cd /content/drive/MyDrive/fsdl-active-learning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bX8zIz-i2pJ",
        "outputId": "e2267864-f51c-4dbd-bc29-d4b229f2a1ef"
      },
      "source": [
        "!pip3 install PyYAML==5.3.1\n",
        "!pip3 install boltons wandb pytorch_lightning==1.2.8\n",
        "!pip3 install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 torchtext==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html # general lab / pytorch installs\n",
        "!pip3 install modAL tensorflow # active learning project\n",
        "!pip install hdbscan\n",
        "\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyYAML==5.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 27.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 22.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 17.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 15.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 14.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=00d7741f83dcd13815c817f8f04a10f3bbb561102288c7382d495b8abf598b91\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built PyYAML\n",
            "Installing collected packages: PyYAML\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.3.1\n",
            "Collecting boltons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e1/e7979a4a6d4b296b5935e926549fff540f7670ddaf09bbf137e2b022c039/boltons-20.2.1-py2.py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 12.8MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5f/45439b4767334b868e1c8c35b1b0ba3747d8c21be77b79f09eed7aa3c72b/wandb-0.10.30-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 17.6MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning==1.2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/99/68da5c6ca999de560036d98c492e507d17996f5eeb7e76ba64acd4bbb142/pytorch_lightning-1.2.8-py3-none-any.whl (841kB)\n",
            "\u001b[K     |████████████████████████████████| 849kB 47.4MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.1MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 63.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.8) (1.19.5)\n",
            "Collecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e8/513cd9d0b1c83dc14cd8f788d05cd6a34758d4fd7e4f9e5ecd5d7d599c95/torchmetrics-0.3.2-py3-none-any.whl (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.8) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.8) (1.8.1+cu101)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.8) (2.4.1)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics>=0.2.0->pytorch_lightning==1.2.8) (20.9)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (1.32.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (1.30.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (0.4.4)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.2.8) (21.2.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics>=0.2.0->pytorch_lightning==1.2.8) (2.4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (3.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools, future\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=8bd0180a6fd5df42ea3c768f3aad576f1d1c929bff6fd562961693d13aba3b10\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=7bbace2db8a93c43b94dfbec2fa435d1e67c1d1b4057a4e928c96d34beae8bba\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=93d8a5e792e6623d82c4b3e1e93764bb582906afa6b1ea467dff9271eca51d65\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built subprocess32 pathtools future\n",
            "Installing collected packages: boltons, sentry-sdk, docker-pycreds, shortuuid, subprocess32, configparser, pathtools, smmap, gitdb, GitPython, wandb, multidict, yarl, async-timeout, aiohttp, fsspec, torchmetrics, future, pytorch-lightning\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed GitPython-3.1.17 aiohttp-3.7.4.post0 async-timeout-3.0.1 boltons-20.2.1 configparser-5.0.2 docker-pycreds-0.4.0 fsspec-2021.4.0 future-0.18.2 gitdb-4.0.7 multidict-5.1.0 pathtools-0.1.2 pytorch-lightning-1.2.8 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 torchmetrics-0.3.2 wandb-0.10.30 yarl-1.6.3\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8MB)\n",
            "\u001b[K     |███████████████████████         | 834.1MB 1.3MB/s eta 0:04:17tcmalloc: large alloc 1147494400 bytes == 0x55ada640a000 @  0x7ff609667615 0x55ad6ce42cdc 0x55ad6cf2252a 0x55ad6ce45afd 0x55ad6cf36fed 0x55ad6ceb9988 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb97f0 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb632a 0x55ad6cf37e36 0x55ad6ceb5853 0x55ad6cf37e36 0x55ad6ceb5853 0x55ad6cf37e36 0x55ad6ceb5853 0x55ad6cf37e36 0x55ad6cfba3e1 0x55ad6cf1a6a9 0x55ad6ce85cc4 0x55ad6ce46559 0x55ad6ceba4f8 0x55ad6ce4730a 0x55ad6ceb53b5 0x55ad6ceb47ad 0x55ad6ce473ea 0x55ad6ceb53b5 0x55ad6ce4730a 0x55ad6ceb53b5\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7MB 1.2MB/s eta 0:01:27tcmalloc: large alloc 1434370048 bytes == 0x55adeaa60000 @  0x7ff609667615 0x55ad6ce42cdc 0x55ad6cf2252a 0x55ad6ce45afd 0x55ad6cf36fed 0x55ad6ceb9988 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb97f0 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb632a 0x55ad6cf37e36 0x55ad6ceb5853 0x55ad6cf37e36 0x55ad6ceb5853 0x55ad6cf37e36 0x55ad6ceb5853 0x55ad6cf37e36 0x55ad6cfba3e1 0x55ad6cf1a6a9 0x55ad6ce85cc4 0x55ad6ce46559 0x55ad6ceba4f8 0x55ad6ce4730a 0x55ad6ceb53b5 0x55ad6ceb47ad 0x55ad6ce473ea 0x55ad6ceb53b5 0x55ad6ce4730a 0x55ad6ceb53b5\n",
            "\u001b[K     |████████████████████████████████| 1156.7MB 1.2MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55ae4024c000 @  0x7ff609667615 0x55ad6ce42cdc 0x55ad6cf2252a 0x55ad6ce45afd 0x55ad6cf36fed 0x55ad6ceb9988 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb560e 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb560e 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb560e 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb560e 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb560e 0x55ad6ce4730a 0x55ad6ceb560e 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb632a 0x55ad6ceb44ae 0x55ad6ce473ea 0x55ad6ceb632a 0x55ad6ceb44ae 0x55ad6ce47a81\n",
            "\u001b[K     |████████████████████████████████| 1156.8MB 15kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 61.2MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/16/ecdb9eb09ec6b8133d6c9536ea9e49cd13c9b5873c8488b8b765a39028da/torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 13.0MB/s \n",
            "\u001b[?25hCollecting torchtext==0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/80/046f0691b296e755ae884df3ca98033cb9afcaf287603b2b7999e94640b8/torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 24.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n",
            "Installing collected packages: torch, torchvision, torchaudio, torchtext\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "Successfully installed torch-1.7.1+cu110 torchaudio-0.7.2 torchtext-0.8.1 torchvision-0.8.2+cu110\n",
            "Collecting modAL\n",
            "  Downloading https://files.pythonhosted.org/packages/76/63/fe3eea804b180ef85b07d4e99cd932d2b0f79db91ff31391b1d465943aa1/modAL-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from modAL) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from modAL) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from modAL) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.7/dist-packages (from modAL) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->modAL) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->modAL) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->modAL) (2018.9)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.30.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (4.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Installing collected packages: modAL\n",
            "Successfully installed modAL-0.4.1\n",
            "Collecting hdbscan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/bb/59a75bc5ac66a9b4f9b8f979e4545af0e98bb1ca4e6ae96b3b956b554223/hdbscan-0.8.27.tar.gz (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 13.8MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.0.1)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.29.23)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.19.5)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.27-cp37-cp37m-linux_x86_64.whl size=2311627 sha256=2594b90d85910d07d74eb06ca39d308fb671c3e8a0c00be3cb045dc495a81088\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/63/fb/314ad6c3b270887a3ecb588b8e5aac50b0fad38ff89bb6dff2\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: hdbscan\n",
            "Successfully installed hdbscan-0.8.27\n",
            "env: PYTHONPATH=.:$PYTHONPATH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr_-Brzm1afQ"
      },
      "source": [
        "#!wandb init # initialize w&b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOMG0PYU5bKC"
      },
      "source": [
        "\n",
        "#import wandb\n",
        "#wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai_cvBue5Pv9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e4b4e1bf-a8c2-4e53-8ceb-e0a58a5e0170"
      },
      "source": [
        "'''\n",
        "run=wandb.init(name='fsdl_active_learning', \n",
        "           project='Active_learning_Wandb_Drought_Watch_random_sampling',\n",
        "           notes='Random Sampling Drought Watch dataset with all Bands, pretrained ResNet50', \n",
        "           tags=['DroughtWatch', 'Active-Learning','ResNet','PyTorch','Random Sampling'])\n",
        "'''           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nrun=wandb.init(name='fsdl_active_learning', \\n           project='Active_learning_Wandb_Drought_Watch_random_sampling',\\n           notes='Random Sampling Drought Watch dataset with all Bands, pretrained ResNet50', \\n           tags=['DroughtWatch', 'Active-Learning','ResNet','PyTorch','Random Sampling'])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw7Tcp8Qiw9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f4eea5-f339-47ea-f06e-bcbb9cfabc3e"
      },
      "source": [
        "\n",
        "#!python training/run_experiment.py --wandb --gpus=1 --max_epochs=1 --num_workers=4 --data_class=DroughtWatch --model_class=ResnetClassifier --batch_size=32 --sampling_method=\"random\"\n",
        "\n",
        "!python training/run_experiment.py --gpus=1 --max_epochs=10 --num_workers=4  --data_class=CassavaDataModule --model_class=ResnetClassifier2 --sampling_method=\"random\" --batch_size=128"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-14 06:07:27.959117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "INIT SETUP CALLED!!\n",
            "___________________\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "2021-05-14 06:07:52.048476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfsdl-active-learning__CassavaDataModulerandom_multi-class_all-channels\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ravindra/fsdl-active-learning2-training\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ravindra/fsdl-active-learning2-training/runs/1mtlu4b2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/fsdl-active-learning2/wandb/run-20210514_060750-1mtlu4b2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Initializing model for active learning iteration 0\n",
            "Overriding n_channels parameter, setting n_channels to 3\n",
            "\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100%|███████████████████████████████████████| 97.8M/97.8M [00:00<00:00, 209MB/s]\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 0:   0%|                                           | 0/48 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric F1_Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 0:  42%|██████████████▏                   | 20/48 [00:11<00:15,  1.78it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  83%|████████████████████████████▎     | 40/48 [00:24<00:04,  1.62it/s]\n",
            "Epoch 0: 100%|██████████████| 48/48 [00:34<00:00,  1.41it/s, loss=1, v_num=u4b2]\n",
            "Epoch 1:  42%|█████▊        | 20/48 [00:10<00:14,  1.94it/s, loss=1, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  83%|███████████▋  | 40/48 [00:23<00:04,  1.73it/s, loss=1, v_num=u4b2]\n",
            "Epoch 1: 100%|████████████| 48/48 [00:31<00:00,  1.53it/s, loss=0.8, v_num=u4b2]\n",
            "Epoch 2:  42%|█████       | 20/48 [00:10<00:14,  1.93it/s, loss=0.8, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  83%|██████████  | 40/48 [00:23<00:04,  1.71it/s, loss=0.8, v_num=u4b2]\n",
            "Epoch 2: 100%|██████████| 48/48 [00:31<00:00,  1.51it/s, loss=0.634, v_num=u4b2]\n",
            "Epoch 3:  42%|████▏     | 20/48 [00:10<00:14,  1.93it/s, loss=0.634, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 40/48 [00:23<00:04,  1.72it/s, loss=0.634, v_num=u4b2]\n",
            "Epoch 3: 100%|██████████| 48/48 [00:31<00:00,  1.54it/s, loss=0.517, v_num=u4b2]\n",
            "Epoch 4:  42%|████▏     | 20/48 [00:10<00:14,  1.96it/s, loss=0.517, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 40/48 [00:22<00:04,  1.75it/s, loss=0.517, v_num=u4b2]\n",
            "Epoch 4: 100%|██████████| 48/48 [00:31<00:00,  1.55it/s, loss=0.425, v_num=u4b2]\n",
            "Epoch 5:  42%|████▏     | 20/48 [00:10<00:14,  1.95it/s, loss=0.425, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 40/48 [00:22<00:04,  1.76it/s, loss=0.425, v_num=u4b2]\n",
            "Epoch 5: 100%|██████████| 48/48 [00:31<00:00,  1.53it/s, loss=0.325, v_num=u4b2]\n",
            "Epoch 6:  42%|████▏     | 20/48 [00:10<00:14,  1.95it/s, loss=0.325, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  83%|████████▎ | 40/48 [00:22<00:04,  1.74it/s, loss=0.325, v_num=u4b2]\n",
            "Epoch 6: 100%|██████████| 48/48 [00:31<00:00,  1.54it/s, loss=0.274, v_num=u4b2]\n",
            "Epoch 7:  42%|████▏     | 20/48 [00:10<00:14,  1.95it/s, loss=0.274, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  83%|████████▎ | 40/48 [00:22<00:04,  1.74it/s, loss=0.274, v_num=u4b2]\n",
            "Epoch 7: 100%|██████████| 48/48 [00:31<00:00,  1.54it/s, loss=0.291, v_num=u4b2]\n",
            "Epoch 8:  42%|████▏     | 20/48 [00:10<00:14,  1.93it/s, loss=0.291, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  83%|████████▎ | 40/48 [00:23<00:04,  1.73it/s, loss=0.291, v_num=u4b2]\n",
            "Epoch 8: 100%|██████████| 48/48 [00:31<00:00,  1.53it/s, loss=0.209, v_num=u4b2]\n",
            "Epoch 9:  42%|████▏     | 20/48 [00:10<00:14,  2.00it/s, loss=0.209, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  83%|████████▎ | 40/48 [00:22<00:04,  1.77it/s, loss=0.209, v_num=u4b2]\n",
            "Epoch 9: 100%|██████████| 48/48 [00:30<00:00,  1.57it/s, loss=0.171, v_num=u4b2]\n",
            "Epoch 9: 100%|██████████| 48/48 [00:30<00:00,  1.57it/s, loss=0.171, v_num=u4b2]\n",
            "Total Unlabelled Pool Size  15406\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 121/121 [01:15<00:00,  1.60it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.5294041037559509,\n",
            " 'test_f1': 0.40778064727783203,\n",
            " 'train_size': 1711.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"random\": \n",
            "-----------------\n",
            "\n",
            "[ 2996  6879  6740 ... 12698  1236  5479]\n",
            "\n",
            "-----------------\n",
            "\n",
            "New train set size 3711\n",
            "New unlabelled pool size 13406\n",
            "Initializing model for active learning iteration 1\n",
            "Overriding n_channels parameter, setting n_channels to 3\n",
            "\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 0:  32%|███▍       | 20/63 [00:16<00:34,  1.25it/s, loss=1.03, v_num=u4b2]/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric F1_Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 0:  63%|██████▉    | 40/63 [00:20<00:12,  1.91it/s, loss=1.03, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  95%|██████████▍| 60/63 [00:34<00:01,  1.73it/s, loss=1.03, v_num=u4b2]\n",
            "Epoch 0: 100%|██████████| 63/63 [00:43<00:00,  1.46it/s, loss=0.889, v_num=u4b2]\n",
            "Epoch 1:  63%|██████▎   | 40/63 [00:20<00:11,  1.97it/s, loss=0.721, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 60/63 [00:33<00:01,  1.82it/s, loss=0.721, v_num=u4b2]\n",
            "Epoch 1: 100%|██████████| 63/63 [00:41<00:00,  1.50it/s, loss=0.684, v_num=u4b2]\n",
            "Epoch 2:  63%|██████▎   | 40/63 [00:20<00:12,  1.91it/s, loss=0.611, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 40/63 [00:31<00:18,  1.26it/s, loss=0.611, v_num=u4b2]\n",
            "Epoch 2:  95%|█████████▌| 60/63 [00:33<00:01,  1.78it/s, loss=0.611, v_num=u4b2]\n",
            "Epoch 2: 100%|██████████| 63/63 [00:41<00:00,  1.51it/s, loss=0.564, v_num=u4b2]\n",
            "Epoch 3:  63%|██████▎   | 40/63 [00:20<00:11,  1.99it/s, loss=0.453, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 60/63 [00:33<00:01,  1.80it/s, loss=0.453, v_num=u4b2]\n",
            "Epoch 3: 100%|██████████| 63/63 [00:41<00:00,  1.51it/s, loss=0.473, v_num=u4b2]\n",
            "Epoch 4:  63%|██████▎   | 40/63 [00:20<00:11,  1.99it/s, loss=0.405, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 60/63 [00:32<00:01,  1.84it/s, loss=0.405, v_num=u4b2]\n",
            "Epoch 4: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s, loss=0.441, v_num=u4b2]\n",
            "Epoch 5:  63%|██████▎   | 40/63 [00:19<00:11,  2.01it/s, loss=0.384, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 60/63 [00:32<00:01,  1.85it/s, loss=0.384, v_num=u4b2]\n",
            "Epoch 5: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s, loss=0.386, v_num=u4b2]\n",
            "Epoch 6:  63%|██████▎   | 40/63 [00:20<00:12,  1.91it/s, loss=0.322, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  95%|█████████▌| 60/63 [00:33<00:01,  1.77it/s, loss=0.322, v_num=u4b2]\n",
            "Epoch 6: 100%|██████████| 63/63 [00:42<00:00,  1.50it/s, loss=0.357, v_num=u4b2]\n",
            "Epoch 7:  63%|██████▎   | 40/63 [00:20<00:12,  1.91it/s, loss=0.256, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  95%|█████████▌| 60/63 [00:33<00:01,  1.79it/s, loss=0.256, v_num=u4b2]\n",
            "Epoch 7: 100%|██████████| 63/63 [00:41<00:00,  1.51it/s, loss=0.248, v_num=u4b2]\n",
            "Epoch 8:  63%|██████▎   | 40/63 [00:19<00:11,  2.01it/s, loss=0.173, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  95%|█████████▌| 60/63 [00:32<00:01,  1.86it/s, loss=0.173, v_num=u4b2]\n",
            "Epoch 8: 100%|██████████| 63/63 [00:40<00:00,  1.57it/s, loss=0.195, v_num=u4b2]\n",
            "Epoch 9:  63%|██████▎   | 40/63 [00:19<00:11,  2.05it/s, loss=0.158, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  95%|█████████▌| 60/63 [00:31<00:01,  1.88it/s, loss=0.158, v_num=u4b2]\n",
            "Epoch 9: 100%|██████████| 63/63 [00:39<00:00,  1.58it/s, loss=0.186, v_num=u4b2]\n",
            "Epoch 9: 100%|██████████| 63/63 [00:39<00:00,  1.58it/s, loss=0.186, v_num=u4b2]\n",
            "Total Unlabelled Pool Size  13406\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 105/105 [01:01<00:00,  1.70it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.5995076894760132,\n",
            " 'test_f1': 0.42676058411598206,\n",
            " 'train_size': 3710.999755859375}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"random\": \n",
            "-----------------\n",
            "\n",
            "[ 7420  4331 12306 ...  1485   985 12843]\n",
            "\n",
            "-----------------\n",
            "\n",
            "New train set size 5711\n",
            "New unlabelled pool size 11406\n",
            "Initializing model for active learning iteration 2\n",
            "Overriding n_channels parameter, setting n_channels to 3\n",
            "\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 0:  51%|█████     | 40/79 [00:27<00:27,  1.44it/s, loss=0.777, v_num=u4b2]/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric F1_Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 0:  76%|███████▌  | 60/79 [00:29<00:09,  2.02it/s, loss=0.777, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  76%|███████▌  | 60/79 [00:39<00:12,  1.50it/s, loss=0.777, v_num=u4b2]\n",
            "Epoch 0: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s, loss=0.777, v_num=u4b2]\n",
            "Epoch 0: 100%|██████████| 79/79 [00:50<00:00,  1.58it/s, loss=0.756, v_num=u4b2]\n",
            "Epoch 1:  76%|████████▎  | 60/79 [00:29<00:09,  2.01it/s, loss=0.58, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100%|███████████| 79/79 [00:48<00:00,  1.63it/s, loss=0.58, v_num=u4b2]\n",
            "Epoch 1: 100%|██████████| 79/79 [00:50<00:00,  1.57it/s, loss=0.573, v_num=u4b2]\n",
            "Epoch 2:  76%|███████▌  | 60/79 [00:29<00:09,  2.00it/s, loss=0.483, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100%|██████████| 79/79 [00:47<00:00,  1.65it/s, loss=0.483, v_num=u4b2]\n",
            "Epoch 2: 100%|██████████| 79/79 [00:50<00:00,  1.58it/s, loss=0.499, v_num=u4b2]\n",
            "Epoch 3:  76%|███████▌  | 60/79 [00:29<00:09,  2.04it/s, loss=0.424, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100%|██████████| 79/79 [00:47<00:00,  1.65it/s, loss=0.424, v_num=u4b2]\n",
            "Epoch 3: 100%|██████████| 79/79 [00:49<00:00,  1.58it/s, loss=0.472, v_num=u4b2]\n",
            "Epoch 4:  76%|████████▎  | 60/79 [00:30<00:09,  2.00it/s, loss=0.39, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100%|███████████| 79/79 [00:46<00:00,  1.70it/s, loss=0.39, v_num=u4b2]\n",
            "Epoch 4: 100%|██████████| 79/79 [00:50<00:00,  1.56it/s, loss=0.414, v_num=u4b2]\n",
            "Epoch 5:  76%|███████▌  | 60/79 [00:30<00:09,  1.96it/s, loss=0.311, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100%|██████████| 79/79 [00:44<00:00,  1.78it/s, loss=0.311, v_num=u4b2]\n",
            "Epoch 5: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, loss=0.335, v_num=u4b2]\n",
            "Epoch 6:  76%|███████▌  | 60/79 [00:32<00:10,  1.86it/s, loss=0.252, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, loss=0.252, v_num=u4b2]\n",
            "Epoch 6: 100%|██████████| 79/79 [00:54<00:00,  1.44it/s, loss=0.281, v_num=u4b2]\n",
            "Epoch 7:  76%|███████▌  | 60/79 [00:30<00:09,  1.95it/s, loss=0.242, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: 100%|██████████| 79/79 [00:46<00:00,  1.70it/s, loss=0.242, v_num=u4b2]\n",
            "Epoch 7: 100%|██████████| 79/79 [00:51<00:00,  1.52it/s, loss=0.239, v_num=u4b2]\n",
            "Epoch 8:  76%|███████▌  | 60/79 [00:30<00:09,  1.95it/s, loss=0.226, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: 100%|██████████| 79/79 [00:44<00:00,  1.77it/s, loss=0.226, v_num=u4b2]\n",
            "Epoch 8: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, loss=0.214, v_num=u4b2]\n",
            "Epoch 9:  76%|███████▌  | 60/79 [00:30<00:09,  1.99it/s, loss=0.163, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: 100%|██████████| 79/79 [00:43<00:00,  1.83it/s, loss=0.163, v_num=u4b2]\n",
            "Epoch 9: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, loss=0.172, v_num=u4b2]\n",
            "Epoch 9: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, loss=0.172, v_num=u4b2]\n",
            "Total Unlabelled Pool Size  11406\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|██████████████████████████████████| 90/90 [00:55<00:00,  1.61it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7786253094673157,\n",
            " 'test_f1': 0.6069836020469666,\n",
            " 'train_size': 5711.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"random\": \n",
            "-----------------\n",
            "\n",
            "[2321 2366 7940 ... 6407 1179 7470]\n",
            "\n",
            "-----------------\n",
            "\n",
            "New train set size 7711\n",
            "New unlabelled pool size 9406\n",
            "Initializing model for active learning iteration 3\n",
            "Overriding n_channels parameter, setting n_channels to 3\n",
            "\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 0:  63%|██████▎   | 60/95 [00:41<00:24,  1.45it/s, loss=0.741, v_num=u4b2]/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric F1_Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 0:  84%|████████▍ | 80/95 [00:41<00:07,  1.93it/s, loss=0.741, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100%|██████████| 95/95 [00:59<00:00,  1.58it/s, loss=0.741, v_num=u4b2]\n",
            "Epoch 0: 100%|██████████| 95/95 [01:01<00:00,  1.54it/s, loss=0.728, v_num=u4b2]\n",
            "Epoch 1:  84%|████████▍ | 80/95 [00:39<00:07,  2.02it/s, loss=0.588, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100%|██████████| 95/95 [00:56<00:00,  1.68it/s, loss=0.588, v_num=u4b2]\n",
            "Epoch 1: 100%|████████████| 95/95 [01:00<00:00,  1.57it/s, loss=0.6, v_num=u4b2]\n",
            "Epoch 2:  84%|████████▍ | 80/95 [00:39<00:07,  2.03it/s, loss=0.551, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100%|██████████| 95/95 [00:54<00:00,  1.74it/s, loss=0.551, v_num=u4b2]\n",
            "Epoch 2: 100%|███████████| 95/95 [01:00<00:00,  1.58it/s, loss=0.57, v_num=u4b2]\n",
            "Epoch 3:  84%|████████▍ | 80/95 [00:38<00:07,  2.06it/s, loss=0.493, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100%|██████████| 95/95 [00:54<00:00,  1.74it/s, loss=0.493, v_num=u4b2]\n",
            "Epoch 3: 100%|████████████| 95/95 [00:58<00:00,  1.62it/s, loss=0.5, v_num=u4b2]\n",
            "Epoch 4:  84%|████████▍ | 80/95 [00:38<00:07,  2.08it/s, loss=0.416, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100%|██████████| 95/95 [00:55<00:00,  1.70it/s, loss=0.416, v_num=u4b2]\n",
            "Epoch 4: 100%|██████████| 95/95 [00:58<00:00,  1.63it/s, loss=0.428, v_num=u4b2]\n",
            "Epoch 5:  84%|████████▍ | 80/95 [00:38<00:07,  2.07it/s, loss=0.393, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100%|██████████| 95/95 [00:57<00:00,  1.66it/s, loss=0.393, v_num=u4b2]\n",
            "Epoch 5: 100%|██████████| 95/95 [00:58<00:00,  1.62it/s, loss=0.392, v_num=u4b2]\n",
            "Epoch 6:  84%|████████▍ | 80/95 [00:38<00:07,  2.08it/s, loss=0.369, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 6:  84%|████████▍ | 80/95 [00:48<00:09,  1.64it/s, loss=0.369, v_num=u4b2]\n",
            "Epoch 6: 100%|██████████| 95/95 [00:50<00:00,  1.87it/s, loss=0.369, v_num=u4b2]\n",
            "Epoch 6: 100%|██████████| 95/95 [00:58<00:00,  1.62it/s, loss=0.377, v_num=u4b2]\n",
            "Epoch 7:  84%|████████▍ | 80/95 [00:38<00:07,  2.08it/s, loss=0.318, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 7:  84%|████████▍ | 80/95 [00:49<00:09,  1.60it/s, loss=0.318, v_num=u4b2]\n",
            "Epoch 7: 100%|██████████| 95/95 [00:50<00:00,  1.87it/s, loss=0.318, v_num=u4b2]\n",
            "Epoch 7: 100%|██████████| 95/95 [00:59<00:00,  1.60it/s, loss=0.336, v_num=u4b2]\n",
            "Epoch 8:  84%|████████▍ | 80/95 [00:41<00:07,  1.94it/s, loss=0.237, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: 100%|██████████| 95/95 [01:00<00:00,  1.57it/s, loss=0.237, v_num=u4b2]\n",
            "Epoch 8: 100%|██████████| 95/95 [01:03<00:00,  1.51it/s, loss=0.238, v_num=u4b2]\n",
            "Epoch 9:  84%|████████▍ | 80/95 [00:41<00:07,  1.93it/s, loss=0.213, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: 100%|██████████| 95/95 [00:57<00:00,  1.65it/s, loss=0.213, v_num=u4b2]\n",
            "Epoch 9: 100%|██████████| 95/95 [01:02<00:00,  1.52it/s, loss=0.204, v_num=u4b2]\n",
            "Epoch 9: 100%|██████████| 95/95 [01:02<00:00,  1.51it/s, loss=0.204, v_num=u4b2]\n",
            "Total Unlabelled Pool Size  9406\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|██████████████████████████████████| 74/74 [00:44<00:00,  1.65it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7073144912719727,\n",
            " 'test_f1': 0.5805424451828003,\n",
            " 'train_size': 7711.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"random\": \n",
            "-----------------\n",
            "\n",
            "[2208 2954  374 ... 2059 6696 9386]\n",
            "\n",
            "-----------------\n",
            "\n",
            "New train set size 9711\n",
            "New unlabelled pool size 7406\n",
            "Initializing model for active learning iteration 4\n",
            "Overriding n_channels parameter, setting n_channels to 3\n",
            "\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 0:  55%|████▉    | 60/110 [00:40<00:33,  1.48it/s, loss=0.668, v_num=u4b2]/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric F1_Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 0:  73%|██████▌  | 80/110 [00:50<00:18,  1.60it/s, loss=0.668, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  91%|███████▎| 100/110 [01:02<00:06,  1.60it/s, loss=0.668, v_num=u4b2]\n",
            "Epoch 0: 100%|████████| 110/110 [01:11<00:00,  1.54it/s, loss=0.687, v_num=u4b2]\n",
            "Epoch 1:  73%|██████▌  | 80/110 [00:51<00:19,  1.56it/s, loss=0.615, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  91%|███████▎| 100/110 [01:04<00:06,  1.55it/s, loss=0.615, v_num=u4b2]\n",
            "Epoch 1: 100%|████████| 110/110 [01:12<00:00,  1.52it/s, loss=0.604, v_num=u4b2]\n",
            "Epoch 2:  73%|███████▎  | 80/110 [00:50<00:18,  1.60it/s, loss=0.55, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 80/110 [01:02<00:23,  1.28it/s, loss=0.55, v_num=u4b2]\n",
            "Epoch 2:  91%|████████▏| 100/110 [01:02<00:06,  1.59it/s, loss=0.55, v_num=u4b2]\n",
            "Epoch 2: 100%|████████| 110/110 [01:10<00:00,  1.55it/s, loss=0.565, v_num=u4b2]\n",
            "Epoch 3:  73%|██████▌  | 80/110 [00:50<00:18,  1.59it/s, loss=0.521, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  91%|███████▎| 100/110 [01:03<00:06,  1.58it/s, loss=0.521, v_num=u4b2]\n",
            "Epoch 3: 100%|█████████| 110/110 [01:11<00:00,  1.54it/s, loss=0.52, v_num=u4b2]\n",
            "Epoch 4:  73%|██████▌  | 80/110 [00:50<00:18,  1.59it/s, loss=0.435, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  91%|███████▎| 100/110 [01:02<00:06,  1.59it/s, loss=0.435, v_num=u4b2]\n",
            "Epoch 4: 100%|████████| 110/110 [01:11<00:00,  1.55it/s, loss=0.475, v_num=u4b2]\n",
            "Epoch 5:  73%|██████▌  | 80/110 [00:52<00:19,  1.53it/s, loss=0.384, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  91%|███████▎| 100/110 [01:05<00:06,  1.52it/s, loss=0.384, v_num=u4b2]\n",
            "Epoch 5: 100%|████████| 110/110 [01:14<00:00,  1.49it/s, loss=0.378, v_num=u4b2]\n",
            "Epoch 6:  73%|██████▌  | 80/110 [00:54<00:20,  1.47it/s, loss=0.306, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  91%|███████▎| 100/110 [01:07<00:06,  1.47it/s, loss=0.306, v_num=u4b2]\n",
            "Epoch 6: 100%|████████| 110/110 [01:16<00:00,  1.45it/s, loss=0.375, v_num=u4b2]\n",
            "Epoch 7:  73%|██████▌  | 80/110 [00:50<00:18,  1.60it/s, loss=0.263, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  91%|███████▎| 100/110 [01:02<00:06,  1.60it/s, loss=0.263, v_num=u4b2]\n",
            "Epoch 7: 100%|████████| 110/110 [01:11<00:00,  1.53it/s, loss=0.303, v_num=u4b2]\n",
            "Epoch 8:  73%|██████▌  | 80/110 [00:54<00:20,  1.47it/s, loss=0.228, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 8:  73%|██████▌  | 80/110 [01:05<00:24,  1.22it/s, loss=0.228, v_num=u4b2]\n",
            "Epoch 8:  91%|███████▎| 100/110 [01:08<00:06,  1.46it/s, loss=0.228, v_num=u4b2]\n",
            "Epoch 8: 100%|████████| 110/110 [01:17<00:00,  1.42it/s, loss=0.211, v_num=u4b2]\n",
            "Epoch 9:  73%|██████▌  | 80/110 [00:54<00:20,  1.46it/s, loss=0.212, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 9:  73%|██████▌  | 80/110 [01:08<00:25,  1.18it/s, loss=0.212, v_num=u4b2]\n",
            "Epoch 9:  91%|███████▎| 100/110 [01:08<00:06,  1.45it/s, loss=0.212, v_num=u4b2]\n",
            "Epoch 9: 100%|████████| 110/110 [01:18<00:00,  1.41it/s, loss=0.194, v_num=u4b2]\n",
            "Epoch 9: 100%|████████| 110/110 [01:18<00:00,  1.41it/s, loss=0.194, v_num=u4b2]\n",
            "Total Unlabelled Pool Size  7406\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|██████████████████████████████████| 58/58 [00:39<00:00,  1.49it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.785579264163971,\n",
            " 'test_f1': 0.5674284100532532,\n",
            " 'train_size': 9711.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"random\": \n",
            "-----------------\n",
            "\n",
            "[4889 1530 1004 ... 3856 4481 1438]\n",
            "\n",
            "-----------------\n",
            "\n",
            "New train set size 11711\n",
            "New unlabelled pool size 5406\n",
            "Initializing model for active learning iteration 5\n",
            "Overriding n_channels parameter, setting n_channels to 3\n",
            "\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 0:  63%|█████▋   | 80/126 [00:58<00:33,  1.36it/s, loss=0.708, v_num=u4b2]/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric F1_Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 0:  79%|██████▎ | 100/126 [01:05<00:17,  1.53it/s, loss=0.708, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  95%|███████▌| 120/126 [01:19<00:03,  1.51it/s, loss=0.708, v_num=u4b2]\n",
            "Epoch 0: 100%|████████| 126/126 [01:28<00:00,  1.43it/s, loss=0.669, v_num=u4b2]\n",
            "Epoch 1:  79%|██████▎ | 100/126 [01:06<00:17,  1.51it/s, loss=0.544, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  79%|██████▎ | 100/126 [01:20<00:20,  1.25it/s, loss=0.544, v_num=u4b2]\n",
            "Epoch 1:  95%|███████▌| 120/126 [01:20<00:04,  1.49it/s, loss=0.544, v_num=u4b2]\n",
            "Epoch 1: 100%|████████| 126/126 [01:29<00:00,  1.40it/s, loss=0.533, v_num=u4b2]\n",
            "Epoch 2:  79%|██████▎ | 100/126 [01:05<00:16,  1.53it/s, loss=0.539, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  95%|███████▌| 120/126 [01:19<00:03,  1.52it/s, loss=0.539, v_num=u4b2]\n",
            "Epoch 2: 100%|████████| 126/126 [01:28<00:00,  1.43it/s, loss=0.543, v_num=u4b2]\n",
            "Epoch 3:  79%|██████▎ | 100/126 [01:05<00:17,  1.52it/s, loss=0.494, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  95%|███████▌| 120/126 [01:20<00:04,  1.50it/s, loss=0.494, v_num=u4b2]\n",
            "Epoch 3: 100%|████████| 126/126 [01:29<00:00,  1.41it/s, loss=0.485, v_num=u4b2]\n",
            "Epoch 4:  79%|██████▎ | 100/126 [01:06<00:17,  1.51it/s, loss=0.471, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  95%|███████▌| 120/126 [01:20<00:04,  1.49it/s, loss=0.471, v_num=u4b2]\n",
            "Epoch 4: 100%|████████| 126/126 [01:29<00:00,  1.40it/s, loss=0.432, v_num=u4b2]\n",
            "Epoch 5:  79%|██████▎ | 100/126 [01:06<00:17,  1.49it/s, loss=0.381, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 5:  79%|██████▎ | 100/126 [01:19<00:20,  1.26it/s, loss=0.381, v_num=u4b2]\n",
            "Epoch 5:  95%|███████▌| 120/126 [01:21<00:04,  1.47it/s, loss=0.381, v_num=u4b2]\n",
            "Epoch 5: 100%|████████| 126/126 [01:30<00:00,  1.39it/s, loss=0.374, v_num=u4b2]\n",
            "Epoch 6:  79%|███████▏ | 100/126 [01:06<00:17,  1.51it/s, loss=0.36, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 6:  79%|███████▏ | 100/126 [01:18<00:20,  1.27it/s, loss=0.36, v_num=u4b2]\n",
            "Epoch 6:  95%|████████▌| 120/126 [01:19<00:03,  1.52it/s, loss=0.36, v_num=u4b2]\n",
            "Epoch 6: 100%|████████| 126/126 [01:27<00:00,  1.45it/s, loss=0.357, v_num=u4b2]\n",
            "Epoch 7:  79%|███████▏ | 100/126 [00:59<00:15,  1.68it/s, loss=0.31, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 7:  79%|███████▏ | 100/126 [01:11<00:18,  1.40it/s, loss=0.31, v_num=u4b2]\n",
            "Epoch 7:  95%|████████▌| 120/126 [01:12<00:03,  1.66it/s, loss=0.31, v_num=u4b2]\n",
            "Epoch 7: 100%|████████| 126/126 [01:20<00:00,  1.57it/s, loss=0.314, v_num=u4b2]\n",
            "Epoch 8:  79%|██████▎ | 100/126 [00:59<00:15,  1.68it/s, loss=0.266, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 8:  79%|██████▎ | 100/126 [01:11<00:18,  1.40it/s, loss=0.266, v_num=u4b2]\n",
            "Epoch 8:  95%|███████▌| 120/126 [01:11<00:03,  1.67it/s, loss=0.266, v_num=u4b2]\n",
            "Epoch 8: 100%|████████| 126/126 [01:19<00:00,  1.58it/s, loss=0.274, v_num=u4b2]\n",
            "Epoch 9:  79%|██████▎ | 100/126 [00:59<00:15,  1.67it/s, loss=0.203, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 9:  79%|██████▎ | 100/126 [01:11<00:18,  1.40it/s, loss=0.203, v_num=u4b2]\n",
            "Epoch 9:  95%|███████▌| 120/126 [01:12<00:03,  1.66it/s, loss=0.203, v_num=u4b2]\n",
            "Epoch 9: 100%|████████| 126/126 [01:20<00:00,  1.57it/s, loss=0.214, v_num=u4b2]\n",
            "Epoch 9: 100%|████████| 126/126 [01:20<00:00,  1.57it/s, loss=0.214, v_num=u4b2]\n",
            "Total Unlabelled Pool Size  5406\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|██████████████████████████████████| 43/43 [00:26<00:00,  1.65it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7375138998031616,\n",
            " 'test_f1': 0.5764180421829224,\n",
            " 'train_size': 11711.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"random\": \n",
            "-----------------\n",
            "\n",
            "[2078 5324 4544 ...  665 5149 1385]\n",
            "\n",
            "-----------------\n",
            "\n",
            "New train set size 13711\n",
            "New unlabelled pool size 3406\n",
            "Initializing model for active learning iteration 6\n",
            "Overriding n_channels parameter, setting n_channels to 3\n",
            "\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 0:  70%|█████▋  | 100/142 [01:05<00:27,  1.52it/s, loss=0.653, v_num=u4b2]/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric F1_Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 0:  85%|██████▊ | 120/142 [01:09<00:12,  1.74it/s, loss=0.653, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  85%|██████▊ | 120/142 [01:20<00:14,  1.50it/s, loss=0.653, v_num=u4b2]\n",
            "Epoch 0:  99%|███████▉| 140/142 [01:22<00:01,  1.70it/s, loss=0.653, v_num=u4b2]\n",
            "Epoch 0: 100%|████████| 142/142 [01:30<00:00,  1.57it/s, loss=0.621, v_num=u4b2]\n",
            "Epoch 1:  85%|██████▊ | 120/142 [01:09<00:12,  1.72it/s, loss=0.566, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  99%|███████▉| 140/142 [01:22<00:01,  1.70it/s, loss=0.566, v_num=u4b2]\n",
            "Epoch 1: 100%|████████| 142/142 [01:30<00:00,  1.57it/s, loss=0.574, v_num=u4b2]\n",
            "Epoch 2:  85%|██████▊ | 120/142 [01:09<00:12,  1.73it/s, loss=0.494, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  99%|███████▉| 140/142 [01:21<00:01,  1.71it/s, loss=0.494, v_num=u4b2]\n",
            "Epoch 2: 100%|████████| 142/142 [01:30<00:00,  1.58it/s, loss=0.556, v_num=u4b2]\n",
            "Epoch 3:  85%|██████▊ | 120/142 [01:09<00:12,  1.74it/s, loss=0.483, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  99%|███████▉| 140/142 [01:21<00:01,  1.71it/s, loss=0.483, v_num=u4b2]\n",
            "Epoch 3: 100%|████████| 142/142 [01:29<00:00,  1.58it/s, loss=0.487, v_num=u4b2]\n",
            "Epoch 4:  85%|██████▊ | 120/142 [01:09<00:12,  1.73it/s, loss=0.422, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  99%|███████▉| 140/142 [01:21<00:01,  1.71it/s, loss=0.422, v_num=u4b2]\n",
            "Epoch 4: 100%|████████| 142/142 [01:30<00:00,  1.57it/s, loss=0.462, v_num=u4b2]\n",
            "Epoch 5:  85%|██████▊ | 120/142 [01:09<00:12,  1.73it/s, loss=0.378, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  99%|███████▉| 140/142 [01:21<00:01,  1.71it/s, loss=0.378, v_num=u4b2]\n",
            "Epoch 5: 100%|████████| 142/142 [01:29<00:00,  1.58it/s, loss=0.362, v_num=u4b2]\n",
            "Epoch 6:  85%|██████▊ | 120/142 [01:09<00:12,  1.74it/s, loss=0.362, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  99%|███████▉| 140/142 [01:21<00:01,  1.71it/s, loss=0.362, v_num=u4b2]\n",
            "Epoch 6: 100%|████████| 142/142 [01:29<00:00,  1.58it/s, loss=0.352, v_num=u4b2]\n",
            "Epoch 7:  85%|██████▊ | 120/142 [01:09<00:12,  1.74it/s, loss=0.289, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  99%|███████▉| 140/142 [01:22<00:01,  1.70it/s, loss=0.289, v_num=u4b2]\n",
            "Epoch 7: 100%|████████| 142/142 [01:30<00:00,  1.57it/s, loss=0.312, v_num=u4b2]\n",
            "Epoch 7: 100%|████████| 142/142 [01:30<00:00,  1.57it/s, loss=0.312, v_num=u4b2]\n",
            "Total Unlabelled Pool Size  3406\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|██████████████████████████████████| 27/27 [00:17<00:00,  1.55it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7610099911689758,\n",
            " 'test_f1': 0.5582097172737122,\n",
            " 'train_size': 13710.9990234375}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"random\": \n",
            "-----------------\n",
            "\n",
            "[ 756  767 1537 ... 3057 2130 1120]\n",
            "\n",
            "-----------------\n",
            "\n",
            "New train set size 15711\n",
            "New unlabelled pool size 1406\n",
            "Initializing model for active learning iteration 7\n",
            "Overriding n_channels parameter, setting n_channels to 3\n",
            "\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 0:  76%|██████  | 120/157 [01:20<00:24,  1.48it/s, loss=0.611, v_num=u4b2]/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric F1_Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 0:  89%|███████▏| 140/157 [01:22<00:09,  1.70it/s, loss=0.611, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100%|████████| 157/157 [01:39<00:00,  1.57it/s, loss=0.611, v_num=u4b2]\n",
            "Epoch 0: 100%|████████| 157/157 [01:44<00:00,  1.50it/s, loss=0.624, v_num=u4b2]\n",
            "Epoch 1:  89%|███████▏| 140/157 [01:23<00:10,  1.67it/s, loss=0.535, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100%|████████| 157/157 [01:43<00:00,  1.51it/s, loss=0.535, v_num=u4b2]\n",
            "Epoch 1: 100%|████████| 157/157 [01:46<00:00,  1.48it/s, loss=0.527, v_num=u4b2]\n",
            "Epoch 2:  89%|███████▏| 140/157 [01:24<00:10,  1.66it/s, loss=0.505, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  89%|███████▏| 140/157 [01:37<00:11,  1.43it/s, loss=0.505, v_num=u4b2]\n",
            "Epoch 2: 100%|████████| 157/157 [01:37<00:00,  1.60it/s, loss=0.505, v_num=u4b2]\n",
            "Epoch 2: 100%|████████| 157/157 [01:46<00:00,  1.47it/s, loss=0.513, v_num=u4b2]\n",
            "Epoch 3:  89%|███████▏| 140/157 [01:22<00:10,  1.69it/s, loss=0.462, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100%|████████| 157/157 [01:41<00:00,  1.55it/s, loss=0.462, v_num=u4b2]\n",
            "Epoch 3: 100%|█████████| 157/157 [01:44<00:00,  1.50it/s, loss=0.45, v_num=u4b2]\n",
            "Epoch 4:  89%|███████▏| 140/157 [01:21<00:09,  1.72it/s, loss=0.427, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100%|████████| 157/157 [01:34<00:00,  1.65it/s, loss=0.427, v_num=u4b2]\n",
            "Epoch 4: 100%|████████| 157/157 [01:42<00:00,  1.53it/s, loss=0.424, v_num=u4b2]\n",
            "Epoch 5:  89%|███████▏| 140/157 [01:20<00:09,  1.73it/s, loss=0.372, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 5:  89%|███████▏| 140/157 [01:32<00:11,  1.51it/s, loss=0.372, v_num=u4b2]\n",
            "Epoch 5: 100%|████████| 157/157 [01:34<00:00,  1.67it/s, loss=0.372, v_num=u4b2]\n",
            "Epoch 5: 100%|██████████| 157/157 [01:42<00:00,  1.54it/s, loss=0.4, v_num=u4b2]\n",
            "Epoch 6:  89%|███████▏| 140/157 [01:19<00:09,  1.75it/s, loss=0.283, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 6:  89%|███████▏| 140/157 [01:30<00:10,  1.55it/s, loss=0.283, v_num=u4b2]\n",
            "Epoch 6: 100%|████████| 157/157 [01:32<00:00,  1.70it/s, loss=0.283, v_num=u4b2]\n",
            "Epoch 6: 100%|██████████| 157/157 [01:40<00:00,  1.56it/s, loss=0.3, v_num=u4b2]\n",
            "Epoch 7:  89%|████████ | 140/157 [01:19<00:09,  1.76it/s, loss=0.29, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: 100%|█████████| 157/157 [01:39<00:00,  1.58it/s, loss=0.29, v_num=u4b2]\n",
            "Epoch 7: 100%|████████| 157/157 [01:40<00:00,  1.57it/s, loss=0.287, v_num=u4b2]\n",
            "Epoch 8:  89%|███████▏| 140/157 [01:18<00:09,  1.78it/s, loss=0.228, v_num=u4b2]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 8:  89%|███████▏| 140/157 [01:29<00:10,  1.57it/s, loss=0.228, v_num=u4b2]\n",
            "Epoch 8: 100%|████████| 157/157 [01:31<00:00,  1.71it/s, loss=0.228, v_num=u4b2]\n",
            "Epoch 8: 100%|████████| 157/157 [01:39<00:00,  1.58it/s, loss=0.223, v_num=u4b2]\n",
            "Epoch 8: 100%|████████| 157/157 [01:39<00:00,  1.58it/s, loss=0.223, v_num=u4b2]\n",
            "Total Unlabelled Pool Size  1406\n",
            "Query Sample size  1406\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|██████████████████████████████████| 11/11 [00:07<00:00,  1.44it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7937411069869995,\n",
            " 'test_f1': 0.6311092376708984,\n",
            " 'train_size': 15711.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"random\": \n",
            "-----------------\n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405]\n",
            "\n",
            "-----------------\n",
            "\n",
            "New train set size 17117\n",
            "New unlabelled pool size 0\n",
            "Initializing model for active learning iteration 8\n",
            "Overriding n_channels parameter, setting n_channels to 3\n",
            "\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/fsdl-active-learning2/wandb/run-20210514_060750-1mtlu4b2/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/fsdl-active-learning2/wandb/run-20210514_060750-1mtlu4b2/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                             train_loss 0.19818\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                              train_acc 0.93419\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                               train_f1 0.88048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                             train_size 15711.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  epoch 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                    trainer/global_step 1107\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                               _runtime 5520\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                             _timestamp 1620977990\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  _step 169\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                               val_loss 0.66131\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                val_acc 0.7979\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                 val_f1 0.61025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                          train_acc_max 0.93419\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                            val_acc_max 0.81636\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                           train_f1_max 0.88048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                             val_f1_max 0.68152\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                         train_acc_best 0.93419\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                           val_acc_best 0.81636\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                          train_f1_best 0.88048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                            val_f1_best 0.68152\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                               test_acc 0.79374\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                test_f1 0.63111\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_loss █▆▄▂▂▁▆▄▃▂▁▅▃▂▂▁▅▄▃▂▂▆▄▃▂▂▆▄▃▂▂▆▄▃▃▆▄▃▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train_acc ▁▃▅▇▇█▃▆▆▇█▄▆▇▇█▄▅▆▇▇▃▅▆▇▇▃▅▆▇▇▃▅▆▆▃▅▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train_f1 ▁▃▄▇▇█▃▅▆▇█▄▅▆▇█▄▅▆▇▇▃▅▆▇▇▂▅▆▆▇▃▅▆▆▃▅▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_size ▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch ▁▃▄▆▇▁▃▄▆▇█▂▃▅▆█▂▃▅▆█▂▃▅▆█▂▃▅▆█▁▃▄▆▁▃▄▆▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step ▁▁▁▂▂▂▁▂▂▃▃▁▂▃▄▄▂▂▃▄▅▂▃▄▅▆▂▃▄▆▇▂▃▅▆▂▃▅▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              val_loss █▂▁▂▁▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               val_acc ▄▅▄▃▄▂▅▆▄▆▃▆▇▅▆▇▇▇▅▆▅▇█▇▆█▇▇█▆▁▆▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val_f1 ▁▅▅▃▅▄▅▆▅▆▄▅▆▆▆▇▆▆▇▆▆▆▇▇▆▇▆▇█▆▄▆█▇▇▆███▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_acc_max ▁▃▅▇▇█▃▆▆▇█▄▆▇▇█▄▅▆▇▇▃▅▆▇▇▃▅▆▇▇▃▅▆▆▃▅▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val_acc_max ▁▂▂▃▃▄▄▄▅▅▅▄▆▆▆▇▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▄▇▇█▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train_f1_max ▁▃▄▇▇█▃▅▆▇█▄▅▆▇█▄▅▆▇▇▃▅▆▇▇▂▅▆▆▇▃▅▆▆▃▅▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_f1_max ▁▄▅▅▅▅▅▅▅▆▆▅▆▆▆▇▆▆▆▇▇▅▇▇▇▇▅▇▇▇▇▆▇▇▇▆████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_acc_best ▇▆█▅▆▆▁▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          val_acc_best ▁▃▆▅▇▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_f1_best ▆▆█▅▆▆▁▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val_f1_best ▁▂▅▅▆▇▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_acc ▁▃█▆█▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               test_f1 ▁▂▇▆▆▆▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 8 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfsdl-active-learning__CassavaDataModulerandom_multi-class_all-channels\u001b[0m: \u001b[34mhttps://wandb.ai/ravindra/fsdl-active-learning2-training/runs/1mtlu4b2\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}