{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "test-active-learning-template-entropy",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravindrabharathi/fsdl-active-learning2/blob/main/notebooks/test_active_learning_template_entropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KLUXCLz3me2",
        "outputId": "e97116dd-6ebb-4557-a99b-3af5fc770923"
      },
      "source": [
        "#!git clone --single-branch --branch pytorch_lab_structure https://github.com/ravindrabharathi/fsdl-active-learning.git # add your own username and pw/pat here\n",
        "!git clone https://github.com/ravindrabharathi/fsdl-active-learning2.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fsdl-active-learning2'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Counting objects: 100% (207/207), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 207 (delta 102), reused 154 (delta 61), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (207/207), 1.08 MiB | 6.03 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVuDwtl8t_Ew",
        "outputId": "e2e957e1-1b7f-46b6-e120-915226592c5b"
      },
      "source": [
        "%cd fsdl-active-learning2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fsdl-active-learning2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ4k36MGtb-K",
        "outputId": "64949067-2bc2-4ed0-c46a-2e8f6c949519"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJTqhmEStdHd"
      },
      "source": [
        "!mkdir './data/processed/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BRIry8pt4Gb"
      },
      "source": [
        "!cp -R '/gdrive/MyDrive/Active-learning/droughtwatch/' './data/processed/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds7QXOu5imsW"
      },
      "source": [
        "# alternative way: if you cloned the repository to your GDrive account, you can mount it here\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive', force_remount=True)\n",
        "#%cd /content/drive/MyDrive/fsdl-active-learning"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bX8zIz-i2pJ",
        "outputId": "64950663-643d-43a0-e613-0f9e0f11f85a"
      },
      "source": [
        "!pip3 install PyYAML==5.3.1\n",
        "!pip3 install boltons wandb pytorch_lightning==1.2.8\n",
        "!pip3 install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 torchtext==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html # general lab / pytorch installs\n",
        "!pip3 install modAL tensorflow # active learning project\n",
        "!pip install hdbscan\n",
        "\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyYAML==5.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 26.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 11.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 4.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=26b60a858a4aa48961b2b2aa3ce70b001d397c5e7e7ba3000e78f0a7d9f97c2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built PyYAML\n",
            "Installing collected packages: PyYAML\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.3.1\n",
            "Collecting boltons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e1/e7979a4a6d4b296b5935e926549fff540f7670ddaf09bbf137e2b022c039/boltons-20.2.1-py2.py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 5.3MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/5a/b037b50f9849212863a2fed313624d8f6f33ffa4ce89dc706e2a0e98c780/wandb-0.10.29-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 5.2MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning==1.2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/99/68da5c6ca999de560036d98c492e507d17996f5eeb7e76ba64acd4bbb142/pytorch_lightning-1.2.8-py3-none-any.whl (841kB)\n",
            "\u001b[K     |████████████████████████████████| 849kB 18.1MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 20.5MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 21.8MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.3.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.8) (2.4.1)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.8) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.8) (1.19.5)\n",
            "Collecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 22.3MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 21.2MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/99/dc59248df9a50349d537ffb3403c1bdc1fa69077109d46feaa0843488001/torchmetrics-0.3.1-py3-none-any.whl (271kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 23.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.8) (4.41.1)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (1.28.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (0.4.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (1.32.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.8) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_lightning==1.2.8) (3.7.4.3)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics>=0.2.0->pytorch_lightning==1.2.8) (20.9)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (3.10.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (1.3.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 18.1MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 17.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.2.8) (20.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics>=0.2.0->pytorch_lightning==1.2.8) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.2.8) (3.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools, future\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=ebb52b28a7663f9c32fed940ec60b141b5e8eb34fc3702c21250c10e9138ce76\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=d8cb197a33e7f084911fd33897da81daba2c6ead48429c8c60d73ee4cdcccf3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=e825cad8b05b12884773a090e54515e038c5a357ac64132cd1a6c6c3e0c5df33\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built subprocess32 pathtools future\n",
            "Installing collected packages: boltons, sentry-sdk, smmap, gitdb, GitPython, docker-pycreds, subprocess32, pathtools, configparser, shortuuid, wandb, multidict, async-timeout, yarl, aiohttp, fsspec, future, torchmetrics, pytorch-lightning\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed GitPython-3.1.14 aiohttp-3.7.4.post0 async-timeout-3.0.1 boltons-20.2.1 configparser-5.0.2 docker-pycreds-0.4.0 fsspec-2021.4.0 future-0.18.2 gitdb-4.0.7 multidict-5.1.0 pathtools-0.1.2 pytorch-lightning-1.2.8 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 torchmetrics-0.3.1 wandb-0.10.29 yarl-1.6.3\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8MB)\n",
            "\u001b[K     |███████████████████████         | 834.1MB 1.2MB/s eta 0:04:35tcmalloc: large alloc 1147494400 bytes == 0x556fd6118000 @  0x7ff439224615 0x556f9cd8806c 0x556f9ce67eba 0x556f9cd8ae8d 0x556f9ce7c99d 0x556f9cdfefe9 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfee50 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfb86a 0x556f9ce7d7c6 0x556f9cdfaee2 0x556f9ce7d7c6 0x556f9cdfaee2 0x556f9ce7d7c6 0x556f9cdfaee2 0x556f9ce7d7c6 0x556f9ceff431 0x556f9ce60049 0x556f9cdcac84 0x556f9cd8b8e9 0x556f9cdffade 0x556f9cd8c69a 0x556f9cdfaa45 0x556f9cdf9e0d 0x556f9cd8c77a 0x556f9cdfaa45 0x556f9cd8c69a 0x556f9cdfaa45\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7MB 1.2MB/s eta 0:01:28tcmalloc: large alloc 1434370048 bytes == 0x55701a76e000 @  0x7ff439224615 0x556f9cd8806c 0x556f9ce67eba 0x556f9cd8ae8d 0x556f9ce7c99d 0x556f9cdfefe9 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfee50 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfb86a 0x556f9ce7d7c6 0x556f9cdfaee2 0x556f9ce7d7c6 0x556f9cdfaee2 0x556f9ce7d7c6 0x556f9cdfaee2 0x556f9ce7d7c6 0x556f9ceff431 0x556f9ce60049 0x556f9cdcac84 0x556f9cd8b8e9 0x556f9cdffade 0x556f9cd8c69a 0x556f9cdfaa45 0x556f9cdf9e0d 0x556f9cd8c77a 0x556f9cdfaa45 0x556f9cd8c69a 0x556f9cdfaa45\n",
            "\u001b[K     |████████████████████████████████| 1156.7MB 1.1MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55706ff5a000 @  0x7ff439224615 0x556f9cd8806c 0x556f9ce67eba 0x556f9cd8ae8d 0x556f9ce7c99d 0x556f9cdfefe9 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfac9e 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfac9e 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfac9e 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfac9e 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfac9e 0x556f9cd8c69a 0x556f9cdfac9e 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfb86a 0x556f9cdf9b0e 0x556f9cd8c77a 0x556f9cdfb86a 0x556f9cdf9b0e 0x556f9cd8ce11\n",
            "\u001b[K     |████████████████████████████████| 1156.8MB 15kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 56kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/16/ecdb9eb09ec6b8133d6c9536ea9e49cd13c9b5873c8488b8b765a39028da/torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 5.2MB/s \n",
            "\u001b[?25hCollecting torchtext==0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/80/046f0691b296e755ae884df3ca98033cb9afcaf287603b2b7999e94640b8/torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 23.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2020.12.5)\n",
            "Installing collected packages: torch, torchvision, torchaudio, torchtext\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "Successfully installed torch-1.7.1+cu110 torchaudio-0.7.2 torchtext-0.8.1 torchvision-0.8.2+cu110\n",
            "Collecting modAL\n",
            "  Downloading https://files.pythonhosted.org/packages/76/63/fe3eea804b180ef85b07d4e99cd932d2b0f79db91ff31391b1d465943aa1/modAL-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from modAL) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from modAL) (1.1.5)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.7/dist-packages (from modAL) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from modAL) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->modAL) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->modAL) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->modAL) (2018.9)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (56.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Installing collected packages: modAL\n",
            "Successfully installed modAL-0.4.1\n",
            "Collecting hdbscan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/bb/59a75bc5ac66a9b4f9b8f979e4545af0e98bb1ca4e6ae96b3b956b554223/hdbscan-0.8.27.tar.gz (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 5.2MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.19.5)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.29.22)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.15.0)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.27-cp37-cp37m-linux_x86_64.whl size=2311699 sha256=719c7bd9f5f59d7ddeda8cd1738a7d98c124725a8d2f064f7aaeb91da0e3a617\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/63/fb/314ad6c3b270887a3ecb588b8e5aac50b0fad38ff89bb6dff2\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: hdbscan\n",
            "Successfully installed hdbscan-0.8.27\n",
            "env: PYTHONPATH=.:$PYTHONPATH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr_-Brzm1afQ"
      },
      "source": [
        "#!wandb init # initialize w&b"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOMG0PYU5bKC"
      },
      "source": [
        "\n",
        "#import wandb\n",
        "#wandb.login()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai_cvBue5Pv9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b7bc7aeb-dc7e-4fed-e036-4776f2d1eb4a"
      },
      "source": [
        "'''\n",
        "run=wandb.init(name='fsdl_active_learning', \n",
        "           project='Active_learning_Wandb_Drought_Watch_random_sampling',\n",
        "           notes='Random Sampling Drought Watch dataset with all Bands, pretrained ResNet50', \n",
        "           tags=['DroughtWatch', 'Active-Learning','ResNet','PyTorch','Random Sampling'])\n",
        "'''           "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nrun=wandb.init(name='fsdl_active_learning', \\n           project='Active_learning_Wandb_Drought_Watch_random_sampling',\\n           notes='Random Sampling Drought Watch dataset with all Bands, pretrained ResNet50', \\n           tags=['DroughtWatch', 'Active-Learning','ResNet','PyTorch','Random Sampling'])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw7Tcp8Qiw9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abcf6357-eed7-4592-c4d8-eb61f0adc33e"
      },
      "source": [
        "\n",
        "#!python training/run_experiment.py --wandb --gpus=1 --max_epochs=1 --num_workers=4 --data_class=DroughtWatch --model_class=ResnetClassifier --batch_size=32 --sampling_method=\"random\"\n",
        "\n",
        "!python training/run_experiment.py --gpus=1 --max_epochs=10 --num_workers=4 --batch_size=128 --sampling_method=\"entropy\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-05 12:50:34.139548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed DroughtWatch dataset on disk does not have correct size, initiating reprocessing\n",
            "Downloading raw dataset from https://storage.googleapis.com/wandb_datasets/dw_train_86K_val_10K.zip to /content/fsdl-active-learning2/data/downloaded/droughtwatch/dw_data.zip...\n",
            "2.00GB [00:44, 48.2MB/s]                \n",
            "Computing SHA-256...\n",
            "tcmalloc: large alloc 2150301696 bytes == 0x563045d68000 @  0x7fa95ea741e7 0x56303e4adf48 0x56303e4789c7 0x56303e5f7655 0x56303e591828 0x56303e47c292 0x56303e55a6ae 0x56303e47bee9 0x56303e56d99d 0x56303e4effe9 0x56303e47d69a 0x56303e4efe50 0x56303e47d69a 0x56303e4eba45 0x56303e47d69a 0x56303e4eba45 0x56303e47d69a 0x56303e4eba45 0x56303e4eae0d 0x56303e47de11 0x56303e4bed39 0x56303e4bbc84 0x56303e56e178 0x56303e47e231 0x56303e4ed1e6 0x56303e4eab0e 0x56303e47de11 0x56303e4c1029 0x56303e47c7f2 0x56303e4efd75 0x56303e47d69a\n",
            "Unzipping DroughtWatch file...\n",
            "Loading train/validation datasets as TF tensor\n",
            "2021-05-05 12:52:07.542052: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-05-05 12:52:07.550837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-05-05 12:52:07.605919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-05 12:52:07.606627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-05-05 12:52:07.606676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-05 12:52:07.671951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-05-05 12:52:07.672053: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-05-05 12:52:07.823023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-05-05 12:52:07.841768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-05-05 12:52:08.015876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-05-05 12:52:08.030715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-05-05 12:52:08.035348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-05-05 12:52:08.035493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-05 12:52:08.036182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-05 12:52:08.039540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-05-05 12:52:08.050442: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-05-05 12:52:08.050575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-05 12:52:08.051164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2021-05-05 12:52:08.051205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-05 12:52:08.051276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-05-05 12:52:08.051292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-05-05 12:52:08.051306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-05-05 12:52:08.051319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-05-05 12:52:08.051335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-05-05 12:52:08.051348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-05-05 12:52:08.051361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-05-05 12:52:08.051419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-05 12:52:08.051970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-05 12:52:08.052656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-05-05 12:52:08.054964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-05 12:52:17.899578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-05-05 12:52:17.899629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-05-05 12:52:17.899639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-05-05 12:52:17.905264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-05 12:52:17.905920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-05 12:52:17.906508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-05-05 12:52:17.906991: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-05-05 12:52:17.907033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14413 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2021-05-05 12:52:18.430138: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-05-05 12:52:18.432570: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "2021-05-05 12:52:28.430211: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 28068 of 90000\n",
            "2021-05-05 12:52:38.429980: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 56283 of 90000\n",
            "2021-05-05 12:52:48.430046: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 84364 of 90000\n",
            "2021-05-05 12:52:49.140292: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:230] Shuffle buffer filled.\n",
            "2021-05-05 12:52:49.153884: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 929500000 exceeds 10% of free system memory.\n",
            "2021-05-05 12:52:53.551356: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 500907550 exceeds 10% of free system memory.\n",
            "Converting train/valildation TF tensors to Numpy\n",
            "Saving train/validation to HDF5 in compressed format...\n",
            "Saving all remaining labeled images to separate HDF5 pool...\n",
            "2021-05-05 12:53:10.800933: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 929500000 exceeds 10% of free system memory.\n",
            "2021-05-05 12:53:43.559268: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 929500000 exceeds 10% of free system memory.\n",
            "2021-05-05 12:54:16.369662: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 929500000 exceeds 10% of free system memory.\n",
            "Cleaning up...\n",
            "INIT SETUP DATA CALLED  \n",
            "-------------\n",
            "\n",
            "tcmalloc: large alloc 3082084352 bytes == 0x563245e8e000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c5f7ce8 0x56303e4bbc25 0x56303e47c8e9 0x56303e4f0ade 0x56303e3bcd14 0x7fa8995290a4 0x56303e47dd1d 0x56303e47c2ff 0x56303e4c0630 0x56303e4c055c 0x56303e563e59 0x56303e4ebfad 0x56303e47d69a 0x56303e4ebc9e 0x56303e4eae0d 0x56303e47de11 0x56303e4bed39 0x56303e4bbc84 0x56303e56e178 0x56303e47e231 0x56303e4ed1e6 0x56303e4eab0e 0x56303e47de11 0x56303e4c1029 0x56303e47c7f2 0x56303e4efd75 0x56303e47d69a 0x56303e4eba45\n",
            "tcmalloc: large alloc 4011589632 bytes == 0x5632fd9dc000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c644d18 0x7fa95c6ec010 0x7fa95c6ec73c 0x7fa95c6ec85d 0x56303e47e2f8 0x7fa95c631ef7 0x56303e47bfd7 0x56303e47bde0 0x56303e4efac2 0x56303e4eab0e 0x56303e47d77a 0x56303e4efe50 0x56303e47d69a 0x56303e4ebc9e 0x56303e4eae0d 0x56303e47de11 0x56303e4bed39 0x56303e4bbc84 0x56303e56e178 0x56303e47e231 0x56303e4ed1e6 0x56303e4eab0e 0x56303e47de11 0x56303e4c1029 0x56303e47c7f2 0x56303e4efd75 0x56303e47d69a 0x56303e4eba45\n",
            "tcmalloc: large alloc 3082084352 bytes == 0x5633ecb9c000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c644d18 0x7fa95c6d73a9 0x7fa95c6d9ab5 0x56303e563e59 0x56303e4ebfad 0x56303e47d69a 0x56303e4ebc9e 0x56303e4eae0d 0x56303e47de11 0x56303e4bed39 0x56303e4bbc84 0x56303e56e178 0x56303e47e231 0x56303e4ed1e6 0x56303e4eab0e 0x56303e47de11 0x56303e4c1029 0x56303e47c7f2 0x56303e4efd75 0x56303e47d69a 0x56303e4eba45 0x56303e4eab0e 0x56303e4ea813 0x56303e5b4592 0x56303e5b490d 0x56303e5b47b6 0x56303e58c103 0x56303e58bdac\n",
            "\n",
            "Scenario:\n",
            "- Multi-class classification\n",
            "- All channels\n",
            "\n",
            "Initial training set size: 20000\n",
            "Initial unlabelled pool size: 66317\n",
            "Validation set size: 10778\n",
            "\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 356MB/s]\n",
            "Adapting first convolutional layer to additional channels\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "2021-05-05 12:56:14.245033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.29\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfsdl-active-learning_entropy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ravindra/fsdl-active-learning\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ravindra/fsdl-active-learning/runs/8lqj2e60\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/fsdl-active-learning2/wandb/run-20210505_125612-8lqj2e60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 0:  66%|█████▎  | 160/242 [01:37<00:49,  1.64it/s, loss=0.947, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  74%|█████▉  | 180/242 [01:41<00:35,  1.77it/s, loss=0.947, v_num=2e60]\n",
            "Epoch 0:  83%|██████▌ | 200/242 [01:45<00:22,  1.89it/s, loss=0.947, v_num=2e60]\n",
            "Epoch 0:  91%|███████▎| 220/242 [01:49<00:10,  2.00it/s, loss=0.947, v_num=2e60]\n",
            "Epoch 0:  99%|███████▉| 240/242 [01:53<00:00,  2.11it/s, loss=0.947, v_num=2e60]\n",
            "Epoch 0: 100%|████████| 242/242 [01:54<00:00,  2.11it/s, loss=0.903, v_num=2e60]\n",
            "Epoch 1:  66%|█████▎  | 160/242 [01:37<00:50,  1.64it/s, loss=0.928, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  74%|█████▉  | 180/242 [01:42<00:35,  1.76it/s, loss=0.928, v_num=2e60]\n",
            "Epoch 1:  83%|██████▌ | 200/242 [01:46<00:22,  1.88it/s, loss=0.928, v_num=2e60]\n",
            "Epoch 1:  91%|███████▎| 220/242 [01:50<00:11,  2.00it/s, loss=0.928, v_num=2e60]\n",
            "Epoch 1:  99%|███████▉| 240/242 [01:54<00:00,  2.10it/s, loss=0.928, v_num=2e60]\n",
            "Epoch 1: 100%|████████| 242/242 [01:55<00:00,  2.10it/s, loss=0.877, v_num=2e60]\n",
            "Epoch 2:  66%|█████▎  | 160/242 [01:37<00:50,  1.64it/s, loss=0.862, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  74%|█████▉  | 180/242 [01:42<00:35,  1.76it/s, loss=0.862, v_num=2e60]\n",
            "Epoch 2:  83%|██████▌ | 200/242 [01:46<00:22,  1.88it/s, loss=0.862, v_num=2e60]\n",
            "Epoch 2:  91%|███████▎| 220/242 [01:50<00:11,  2.00it/s, loss=0.862, v_num=2e60]\n",
            "Epoch 2:  99%|███████▉| 240/242 [01:54<00:00,  2.10it/s, loss=0.862, v_num=2e60]\n",
            "Epoch 2: 100%|████████| 242/242 [01:55<00:00,  2.10it/s, loss=0.859, v_num=2e60]\n",
            "Epoch 3:  66%|█████▎  | 160/242 [01:37<00:50,  1.64it/s, loss=0.837, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  74%|█████▉  | 180/242 [01:42<00:35,  1.76it/s, loss=0.837, v_num=2e60]\n",
            "Epoch 3:  83%|██████▌ | 200/242 [01:45<00:22,  1.89it/s, loss=0.837, v_num=2e60]\n",
            "Epoch 3:  91%|███████▎| 220/242 [01:49<00:10,  2.00it/s, loss=0.837, v_num=2e60]\n",
            "Epoch 3:  99%|███████▉| 240/242 [01:53<00:00,  2.11it/s, loss=0.837, v_num=2e60]\n",
            "Epoch 3: 100%|████████| 242/242 [01:54<00:00,  2.11it/s, loss=0.843, v_num=2e60]\n",
            "Epoch 4:  66%|█████▎  | 160/242 [01:37<00:49,  1.64it/s, loss=0.807, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  74%|█████▉  | 180/242 [01:41<00:35,  1.77it/s, loss=0.807, v_num=2e60]\n",
            "Epoch 4:  83%|██████▌ | 200/242 [01:45<00:22,  1.89it/s, loss=0.807, v_num=2e60]\n",
            "Epoch 4:  91%|███████▎| 220/242 [01:49<00:10,  2.00it/s, loss=0.807, v_num=2e60]\n",
            "Epoch 4:  99%|███████▉| 240/242 [01:53<00:00,  2.11it/s, loss=0.807, v_num=2e60]\n",
            "Epoch 4: 100%|████████| 242/242 [01:54<00:00,  2.11it/s, loss=0.803, v_num=2e60]\n",
            "Epoch 5:  66%|█████▎  | 160/242 [01:37<00:50,  1.64it/s, loss=0.798, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  74%|█████▉  | 180/242 [01:42<00:35,  1.76it/s, loss=0.798, v_num=2e60]\n",
            "Epoch 5:  83%|██████▌ | 200/242 [01:45<00:22,  1.89it/s, loss=0.798, v_num=2e60]\n",
            "Epoch 5:  91%|███████▎| 220/242 [01:49<00:10,  2.00it/s, loss=0.798, v_num=2e60]\n",
            "Epoch 5:  99%|███████▉| 240/242 [01:53<00:00,  2.11it/s, loss=0.798, v_num=2e60]\n",
            "Epoch 5: 100%|████████| 242/242 [01:54<00:00,  2.11it/s, loss=0.786, v_num=2e60]\n",
            "Epoch 6:  66%|█████▎  | 160/242 [01:37<00:49,  1.64it/s, loss=0.794, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  74%|█████▉  | 180/242 [01:41<00:35,  1.77it/s, loss=0.794, v_num=2e60]\n",
            "Epoch 6:  83%|██████▌ | 200/242 [01:45<00:22,  1.89it/s, loss=0.794, v_num=2e60]\n",
            "Epoch 6:  91%|███████▎| 220/242 [01:49<00:10,  2.00it/s, loss=0.794, v_num=2e60]\n",
            "Epoch 6:  99%|███████▉| 240/242 [01:53<00:00,  2.11it/s, loss=0.794, v_num=2e60]\n",
            "Epoch 6: 100%|████████| 242/242 [01:54<00:00,  2.11it/s, loss=0.762, v_num=2e60]\n",
            "Epoch 7:  66%|█████▎  | 160/242 [01:37<00:49,  1.64it/s, loss=0.733, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  74%|█████▉  | 180/242 [01:42<00:35,  1.76it/s, loss=0.733, v_num=2e60]\n",
            "Epoch 7:  83%|██████▌ | 200/242 [01:45<00:22,  1.89it/s, loss=0.733, v_num=2e60]\n",
            "Epoch 7:  91%|███████▎| 220/242 [01:49<00:10,  2.00it/s, loss=0.733, v_num=2e60]\n",
            "Epoch 7:  99%|███████▉| 240/242 [01:53<00:00,  2.11it/s, loss=0.733, v_num=2e60]\n",
            "Epoch 7: 100%|████████| 242/242 [01:54<00:00,  2.11it/s, loss=0.729, v_num=2e60]\n",
            "Epoch 8:  66%|█████▎  | 160/242 [01:37<00:50,  1.64it/s, loss=0.692, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  74%|█████▉  | 180/242 [01:42<00:35,  1.76it/s, loss=0.692, v_num=2e60]\n",
            "Epoch 8:  83%|██████▌ | 200/242 [01:45<00:22,  1.89it/s, loss=0.692, v_num=2e60]\n",
            "Epoch 8:  91%|███████▎| 220/242 [01:49<00:10,  2.00it/s, loss=0.692, v_num=2e60]\n",
            "Epoch 8:  99%|███████▉| 240/242 [01:53<00:00,  2.11it/s, loss=0.692, v_num=2e60]\n",
            "Epoch 8: 100%|████████| 242/242 [01:54<00:00,  2.11it/s, loss=0.735, v_num=2e60]\n",
            "Epoch 9:  66%|█████▎  | 160/242 [01:37<00:49,  1.64it/s, loss=0.658, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  74%|█████▉  | 180/242 [01:41<00:35,  1.77it/s, loss=0.658, v_num=2e60]\n",
            "Epoch 9:  83%|██████▌ | 200/242 [01:45<00:22,  1.89it/s, loss=0.658, v_num=2e60]\n",
            "Epoch 9:  91%|███████▎| 220/242 [01:49<00:10,  2.00it/s, loss=0.658, v_num=2e60]\n",
            "Epoch 9:  99%|███████▉| 240/242 [01:53<00:00,  2.11it/s, loss=0.658, v_num=2e60]\n",
            "Epoch 9: 100%|████████| 242/242 [01:54<00:00,  2.11it/s, loss=0.682, v_num=2e60]\n",
            "Epoch 9: 100%|████████| 242/242 [01:55<00:00,  2.09it/s, loss=0.682, v_num=2e60]\n",
            "Total Unlabelled Pool Size  66317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 519/519 [01:42<00:00,  5.05it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.659122109413147, 'train_size': 20000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[22900 64641 61672 ... 34024 10791 31557]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "tcmalloc: large alloc 2989137920 bytes == 0x563245e8e000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c644d18 0x7fa95c6d73a9 0x7fa95c6d9ab5 0x56303e563e59 0x56303e4ebfad 0x56303e47d69a 0x56303e4ebc9e 0x56303e47d69a 0x56303e4eba45 0x56303e4eab0e 0x56303e4ea813 0x56303e5b4592 0x56303e5b490d 0x56303e5b47b6 0x56303e58c103 0x56303e58bdac 0x7fa95d85ebf7 0x56303e58bc8a\n",
            " New train set size  22000\n",
            "New unlabelled pool size  64317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  70%|█████▌  | 180/257 [01:47<00:45,  1.68it/s, loss=0.645, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  78%|██████▏ | 200/257 [01:51<00:31,  1.79it/s, loss=0.645, v_num=2e60]\n",
            "Epoch 9:  86%|██████▊ | 220/257 [01:55<00:19,  1.90it/s, loss=0.645, v_num=2e60]\n",
            "Epoch 9:  93%|███████▍| 240/257 [01:59<00:08,  2.01it/s, loss=0.645, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.86it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 257/257 [02:04<00:00,  2.06it/s, loss=0.655, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  64317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 503/503 [01:39<00:00,  5.05it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.4203709661960602, 'train_size': 22000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[34015 19084 42309 ... 26609  8499 41873]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "tcmalloc: large alloc 2896183296 bytes == 0x56333504e000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c644d18 0x7fa95c6d73a9 0x7fa95c6d9ab5 0x56303e563e59 0x56303e4ebfad 0x56303e47d69a 0x56303e4ebc9e 0x56303e47d69a 0x56303e4eba45 0x56303e4eab0e 0x56303e4ea813 0x56303e5b4592 0x56303e5b490d 0x56303e5b47b6 0x56303e58c103 0x56303e58bdac 0x7fa95d85ebf7 0x56303e58bc8a\n",
            " New train set size  24000\n",
            "New unlabelled pool size  62317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  73%|█████▊  | 200/273 [01:56<00:42,  1.71it/s, loss=0.625, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  81%|██████▍ | 220/273 [02:01<00:29,  1.81it/s, loss=0.625, v_num=2e60]\n",
            "Epoch 9:  88%|███████ | 240/273 [02:05<00:17,  1.91it/s, loss=0.625, v_num=2e60]\n",
            "Epoch 9:  95%|███████▌| 260/273 [02:09<00:06,  2.01it/s, loss=0.625, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.86it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 273/273 [02:14<00:00,  2.03it/s, loss=0.638, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  62317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 487/487 [01:36<00:00,  5.02it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.5517595410346985, 'train_size': 24000.001953125}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[60486 15743 20437 ... 48172 55188 19017]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "tcmalloc: large alloc 2803236864 bytes == 0x563245e8e000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c644d18 0x7fa95c6d73a9 0x7fa95c6d9ab5 0x56303e563e59 0x56303e4ebfad 0x56303e47d69a 0x56303e4ebc9e 0x56303e47d69a 0x56303e4eba45 0x56303e4eab0e 0x56303e4ea813 0x56303e5b4592 0x56303e5b490d 0x56303e5b47b6 0x56303e58c103 0x56303e58bdac 0x7fa95d85ebf7 0x56303e58bc8a\n",
            " New train set size  26000\n",
            "New unlabelled pool size  60317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  76%|██████  | 220/289 [02:06<00:39,  1.74it/s, loss=0.623, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  83%|██████▋ | 240/289 [02:11<00:26,  1.83it/s, loss=0.623, v_num=2e60]\n",
            "Epoch 9:  90%|███████▏| 260/289 [02:15<00:15,  1.93it/s, loss=0.623, v_num=2e60]\n",
            "Epoch 9:  97%|███████▊| 280/289 [02:18<00:04,  2.02it/s, loss=0.623, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.87it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 289/289 [02:23<00:00,  2.01it/s, loss=0.615, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  60317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 472/472 [01:33<00:00,  5.05it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.5957358479499817, 'train_size': 25999.998046875}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[52321 30951 49798 ... 55489 15149 41965]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "tcmalloc: large alloc 2710290432 bytes == 0x56333504e000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c644d18 0x7fa95c6d73a9 0x7fa95c6d9ab5 0x56303e563e59 0x56303e4ebfad 0x56303e47d69a 0x56303e4ebc9e 0x56303e47d69a 0x56303e4eba45 0x56303e4eab0e 0x56303e4ea813 0x56303e5b4592 0x56303e5b490d 0x56303e5b47b6 0x56303e58c103 0x56303e58bdac 0x7fa95d85ebf7 0x56303e58bc8a\n",
            " New train set size  28000\n",
            "New unlabelled pool size  58317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  72%|█████▊  | 220/304 [02:16<00:52,  1.61it/s, loss=0.603, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  79%|██████▎ | 240/304 [02:20<00:37,  1.71it/s, loss=0.603, v_num=2e60]\n",
            "Epoch 9:  86%|██████▊ | 260/304 [02:24<00:24,  1.80it/s, loss=0.603, v_num=2e60]\n",
            "Epoch 9:  92%|███████▎| 280/304 [02:28<00:12,  1.88it/s, loss=0.603, v_num=2e60]\n",
            "Epoch 9:  99%|███████▉| 300/304 [02:32<00:02,  1.97it/s, loss=0.603, v_num=2e60]\n",
            "Epoch 9: 100%|████████| 304/304 [02:33<00:00,  1.98it/s, loss=0.586, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  58317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 456/456 [01:30<00:00,  5.04it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.6882041096687317, 'train_size': 28000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[17564 46055 36868 ... 35913 26714 49454]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  30000\n",
            "New unlabelled pool size  56317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  75%|██████  | 240/320 [02:26<00:48,  1.64it/s, loss=0.587, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  81%|██████▌ | 260/320 [02:30<00:34,  1.73it/s, loss=0.587, v_num=2e60]\n",
            "Epoch 9:  88%|███████ | 280/320 [02:34<00:22,  1.81it/s, loss=0.587, v_num=2e60]\n",
            "Epoch 9:  94%|███████▌| 300/320 [02:38<00:10,  1.89it/s, loss=0.587, v_num=2e60]\n",
            "Epoch 9: 100%|████████| 320/320 [02:42<00:00,  1.97it/s, loss=0.587, v_num=2e60]\n",
            "Epoch 9: 100%|████████| 320/320 [02:43<00:00,  1.96it/s, loss=0.585, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  56317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 440/440 [01:27<00:00,  5.03it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7215050458908081, 'train_size': 30000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[28506 42152 31775 ... 23595 46676 10327]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  32000\n",
            "New unlabelled pool size  54317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  78%|██████▏ | 260/335 [02:35<00:44,  1.67it/s, loss=0.585, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  84%|██████▋ | 280/335 [02:40<00:31,  1.75it/s, loss=0.585, v_num=2e60]\n",
            "Epoch 9:  90%|███████▏| 300/335 [02:44<00:19,  1.83it/s, loss=0.585, v_num=2e60]\n",
            "Epoch 9:  96%|███████▋| 320/335 [02:48<00:07,  1.90it/s, loss=0.585, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.86it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 335/335 [02:53<00:00,  1.94it/s, loss=0.587, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  54317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 425/425 [01:24<00:00,  5.04it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.6940184235572815, 'train_size': 32000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 3198  1690 18380 ... 48668 18801 32503]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  34000\n",
            "New unlabelled pool size  52317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  80%|██████▍ | 280/351 [02:45<00:41,  1.69it/s, loss=0.586, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  85%|██████▊ | 300/351 [02:49<00:28,  1.77it/s, loss=0.586, v_num=2e60]\n",
            "Epoch 9:  91%|███████▎| 320/351 [02:53<00:16,  1.84it/s, loss=0.586, v_num=2e60]\n",
            "Epoch 9:  97%|███████▋| 340/351 [02:57<00:05,  1.91it/s, loss=0.586, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.86it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 351/351 [03:02<00:00,  1.92it/s, loss=0.594, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  52317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 409/409 [01:21<00:00,  5.04it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7404667735099792, 'train_size': 34000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 5982 41728 30473 ... 32144 50913 27320]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  36000\n",
            "New unlabelled pool size  50317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  82%|██████▌ | 300/367 [02:54<00:39,  1.72it/s, loss=0.566, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  87%|██████▉ | 320/367 [02:59<00:26,  1.78it/s, loss=0.566, v_num=2e60]\n",
            "Epoch 9:  93%|███████▍| 340/367 [03:03<00:14,  1.85it/s, loss=0.566, v_num=2e60]\n",
            "Epoch 9:  98%|███████▊| 360/367 [03:07<00:03,  1.92it/s, loss=0.566, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.86it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 367/367 [03:12<00:00,  1.91it/s, loss=0.579, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  50317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 394/394 [01:18<00:00,  5.04it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.709442138671875, 'train_size': 36000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[27221 43243 27051 ...  2066 18540 19357]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  38000\n",
            "New unlabelled pool size  48317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  79%|██████▎ | 300/382 [03:04<00:50,  1.62it/s, loss=0.567, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  84%|██████▋ | 320/382 [03:09<00:36,  1.69it/s, loss=0.567, v_num=2e60]\n",
            "Epoch 9:  89%|███████ | 340/382 [03:13<00:23,  1.76it/s, loss=0.567, v_num=2e60]\n",
            "Epoch 9:  94%|███████▌| 360/382 [03:16<00:12,  1.83it/s, loss=0.567, v_num=2e60]\n",
            "Epoch 9:  99%|███████▉| 380/382 [03:20<00:01,  1.89it/s, loss=0.567, v_num=2e60]\n",
            "Epoch 9: 100%|████████| 382/382 [03:21<00:00,  1.89it/s, loss=0.581, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  48317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 378/378 [01:14<00:00,  5.04it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7596911787986755, 'train_size': 38000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[45627 45289 44107 ...  3060 10340  8702]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  40000\n",
            "New unlabelled pool size  46317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  80%|██████▍ | 320/398 [03:14<00:47,  1.65it/s, loss=0.542, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  85%|██████▊ | 340/398 [03:18<00:33,  1.71it/s, loss=0.542, v_num=2e60]\n",
            "Epoch 9:  90%|███████▏| 360/398 [03:22<00:21,  1.78it/s, loss=0.542, v_num=2e60]\n",
            "Epoch 9:  95%|███████▋| 380/398 [03:26<00:09,  1.84it/s, loss=0.542, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.87it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 398/398 [03:31<00:00,  1.88it/s, loss=0.587, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  46317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 362/362 [01:12<00:00,  5.01it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7508690357208252, 'train_size': 40000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[41137 37580 25251 ... 14654 16117 24426]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  42000\n",
            "New unlabelled pool size  44317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  82%|██████▌ | 340/414 [03:24<00:44,  1.66it/s, loss=0.551, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  87%|██████▉ | 360/414 [03:28<00:31,  1.73it/s, loss=0.551, v_num=2e60]\n",
            "Epoch 9:  92%|███████▎| 380/414 [03:32<00:19,  1.79it/s, loss=0.551, v_num=2e60]\n",
            "Epoch 9:  97%|███████▋| 400/414 [03:36<00:07,  1.85it/s, loss=0.551, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.86it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 414/414 [03:41<00:00,  1.87it/s, loss=0.574, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  44317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 347/347 [01:08<00:00,  5.04it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7535257339477539, 'train_size': 42000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[40359 34421 25514 ... 12086 41755 33152]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            " New train set size  44000\n",
            "New unlabelled pool size  42317\n",
            "Epoch 9:  84%|██████▋ | 360/429 [03:33<00:40,  1.68it/s, loss=0.533, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  89%|███████ | 380/429 [03:38<00:28,  1.74it/s, loss=0.533, v_num=2e60]\n",
            "Epoch 9:  93%|███████▍| 400/429 [03:42<00:16,  1.80it/s, loss=0.533, v_num=2e60]\n",
            "Epoch 9:  98%|███████▊| 420/429 [03:46<00:04,  1.86it/s, loss=0.533, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.88it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 429/429 [03:51<00:00,  1.86it/s, loss=0.535, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  42317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 331/331 [01:05<00:00,  5.03it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7022237181663513, 'train_size': 44000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[24733 28842 32524 ... 20789 14835  8721]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  46000\n",
            "New unlabelled pool size  40317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  81%|██████▍ | 360/445 [03:43<00:52,  1.61it/s, loss=0.509, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  90%|███████▏| 400/445 [03:47<00:25,  1.75it/s, loss=0.509, v_num=2e60]\n",
            "Validating:  47%|██████████████▌                | 40/85 [00:08<00:09,  4.63it/s]\u001b[A\n",
            "Epoch 9:  99%|███████▉| 440/445 [03:55<00:02,  1.87it/s, loss=0.509, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.86it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 445/445 [04:00<00:00,  1.85it/s, loss=0.509, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  40317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 315/315 [01:02<00:00,  5.02it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.799836277961731, 'train_size': 46000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[30142 22484 12977 ... 37368 29990  4698]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  48000\n",
            "New unlabelled pool size  38317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  83%|██████▌ | 380/460 [03:53<00:49,  1.63it/s, loss=0.516, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  87%|██████▉ | 400/460 [03:57<00:35,  1.68it/s, loss=0.516, v_num=2e60]\n",
            "Epoch 9:  91%|███████▎| 420/460 [04:01<00:23,  1.74it/s, loss=0.516, v_num=2e60]\n",
            "Epoch 9:  96%|███████▋| 440/460 [04:05<00:11,  1.79it/s, loss=0.516, v_num=2e60]\n",
            "Epoch 9: 100%|████████| 460/460 [04:09<00:00,  1.84it/s, loss=0.516, v_num=2e60]\n",
            "Epoch 9: 100%|████████| 460/460 [04:10<00:00,  1.84it/s, loss=0.503, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  38317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 300/300 [00:59<00:00,  5.02it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.821489155292511, 'train_size': 48000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 2721 14860 34110 ... 27329 10101 34680]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  50000\n",
            "New unlabelled pool size  36317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  84%|██████▋ | 400/476 [04:02<00:46,  1.65it/s, loss=0.518, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  88%|███████ | 420/476 [04:07<00:32,  1.70it/s, loss=0.518, v_num=2e60]\n",
            "Epoch 9:  92%|███████▍| 440/476 [04:11<00:20,  1.75it/s, loss=0.518, v_num=2e60]\n",
            "Epoch 9:  97%|███████▋| 460/476 [04:14<00:08,  1.80it/s, loss=0.518, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.87it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 476/476 [04:19<00:00,  1.83it/s, loss=0.538, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  36317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 284/284 [00:56<00:00,  5.03it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8262796998023987, 'train_size': 50000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[26551 24837 32107 ...  3745 17621 12698]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  52000\n",
            "New unlabelled pool size  34317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  85%|██████▊ | 420/492 [04:12<00:43,  1.66it/s, loss=0.502, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  89%|███████▏| 440/492 [04:17<00:30,  1.71it/s, loss=0.502, v_num=2e60]\n",
            "Epoch 9:  93%|███████▍| 460/492 [04:21<00:18,  1.76it/s, loss=0.502, v_num=2e60]\n",
            "Epoch 9:  98%|███████▊| 480/492 [04:24<00:06,  1.81it/s, loss=0.502, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.88it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 492/492 [04:29<00:00,  1.82it/s, loss=0.517, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  34317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 269/269 [00:53<00:00,  5.03it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8376606106758118, 'train_size': 52000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 2659 30269  8168 ... 23374 14540  9018]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  54000\n",
            "New unlabelled pool size  32317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  87%|██████▉ | 440/507 [04:22<00:39,  1.68it/s, loss=0.518, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  91%|███████▎| 460/507 [04:26<00:27,  1.73it/s, loss=0.518, v_num=2e60]\n",
            "Epoch 9:  95%|███████▌| 480/507 [04:30<00:15,  1.77it/s, loss=0.518, v_num=2e60]\n",
            "Epoch 9:  99%|███████▉| 500/507 [04:34<00:03,  1.82it/s, loss=0.518, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.87it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 507/507 [04:39<00:00,  1.81it/s, loss=0.507, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  32317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 253/253 [00:50<00:00,  5.01it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8587430715560913, 'train_size': 54000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[23290 31948  9257 ... 24188   821 25218]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  56000\n",
            "New unlabelled pool size  30317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  84%|████████▍ | 440/523 [04:31<00:51,  1.62it/s, loss=0.5, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  88%|████████▊ | 460/523 [04:36<00:37,  1.67it/s, loss=0.5, v_num=2e60]\n",
            "Epoch 9:  92%|█████████▏| 480/523 [04:40<00:25,  1.71it/s, loss=0.5, v_num=2e60]\n",
            "Epoch 9:  96%|█████████▌| 500/523 [04:43<00:13,  1.76it/s, loss=0.5, v_num=2e60]\n",
            "Epoch 9:  99%|█████████▉| 520/523 [04:47<00:01,  1.81it/s, loss=0.5, v_num=2e60]\n",
            "Epoch 9: 100%|████████| 523/523 [04:48<00:00,  1.81it/s, loss=0.512, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  30317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 237/237 [00:47<00:00,  5.01it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8626512885093689, 'train_size': 56000.00390625}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 7957  3773  5827 ... 22384  5405 18187]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  58000\n",
            "New unlabelled pool size  28317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  85%|██████▊ | 460/539 [04:41<00:48,  1.63it/s, loss=0.444, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  89%|███████ | 480/539 [04:45<00:35,  1.68it/s, loss=0.444, v_num=2e60]\n",
            "Epoch 9:  93%|███████▍| 500/539 [04:49<00:22,  1.72it/s, loss=0.444, v_num=2e60]\n",
            "Epoch 9:  96%|███████▋| 520/539 [04:53<00:10,  1.77it/s, loss=0.444, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.87it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 539/539 [04:58<00:00,  1.80it/s, loss=0.425, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  28317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 222/222 [00:44<00:00,  5.02it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8775647282600403, 'train_size': 57999.99609375}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 9976  5655 24367 ...  8425  6889 14066]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "tcmalloc: large alloc 2788507648 bytes == 0x5632e8556000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c644d18 0x7fa95c6ec010 0x7fa95c6ec73c 0x7fa95c6ec85d 0x56303e47e2f8 0x7fa95c631ef7 0x56303e47bfd7 0x56303e47bde0 0x56303e4efac2 0x56303e4eab0e 0x56303e47d77a 0x56303e4efe50 0x56303e47d69a 0x56303e4ebc9e 0x56303e47d69a 0x56303e4eba45 0x56303e4eab0e 0x56303e4ea813 0x56303e5b4592 0x56303e5b490d 0x56303e5b47b6 0x56303e58c103 0x56303e58bdac 0x7fa95d85ebf7 0x56303e58bc8a\n",
            " New train set size  60000\n",
            "New unlabelled pool size  26317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:  87%|██████▉ | 480/554 [04:51<00:44,  1.65it/s, loss=0.478, v_num=2e60]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  90%|███████▏| 500/554 [04:55<00:31,  1.69it/s, loss=0.478, v_num=2e60]\n",
            "Epoch 9:  94%|███████▌| 520/554 [04:59<00:19,  1.74it/s, loss=0.478, v_num=2e60]\n",
            "Epoch 9:  97%|███████▊| 540/554 [05:03<00:07,  1.78it/s, loss=0.478, v_num=2e60]\n",
            "Validating:  94%|█████████████████████████████▏ | 80/85 [00:16<00:01,  4.87it/s]\u001b[A\n",
            "Epoch 9: 100%|████████| 554/554 [05:08<00:00,  1.80it/s, loss=0.489, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  26317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 206/206 [00:41<00:00,  5.01it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7574191689491272, 'train_size': 60000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 4188  8503 19556 ... 12623 20862  7404]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  62000\n",
            "New unlabelled pool size  24317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:   4%|█▏                               | 20/570 [00:01<00:33, 16.30it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   7%|██▎                              | 40/570 [00:05<01:17,  6.86it/s]\n",
            "Epoch 9:  11%|███▍                             | 60/570 [00:09<01:22,  6.15it/s]\n",
            "Epoch 9:  14%|████▋                            | 80/570 [00:13<01:23,  5.85it/s]\n",
            "Epoch 9:  18%|█████▌                          | 100/570 [00:17<01:22,  5.69it/s]\n",
            "Epoch 9:  21%|█▋      | 120/570 [00:18<01:09,  6.44it/s, loss=0.483, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  24317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 190/190 [00:38<00:00,  4.97it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8532713651657104, 'train_size': 62000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[21023 11482 10036 ...  1661  6262  1986]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  64000\n",
            "New unlabelled pool size  22317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:   3%|█▏                               | 20/585 [00:01<00:33, 17.08it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   7%|██▎                              | 40/585 [00:05<01:16,  7.08it/s]\n",
            "Epoch 9:  10%|███▍                             | 60/585 [00:09<01:23,  6.26it/s]\n",
            "Epoch 9:  14%|████▌                            | 80/585 [00:13<01:25,  5.92it/s]\n",
            "Epoch 9:  17%|█████▍                          | 100/585 [00:17<01:24,  5.74it/s]\n",
            "Epoch 9:  21%|█▋      | 120/585 [00:18<01:11,  6.50it/s, loss=0.487, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  22317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 175/175 [00:35<00:00,  4.98it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.9029439687728882, 'train_size': 64000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 7845 12106 18583 ... 12918  3325  2358]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  66000\n",
            "New unlabelled pool size  20317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:   3%|█                                | 20/601 [00:01<00:34, 16.73it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   7%|██▏                              | 40/601 [00:05<01:19,  7.10it/s]\n",
            "Epoch 9:  10%|███▎                             | 60/601 [00:09<01:26,  6.28it/s]\n",
            "Epoch 9:  13%|████▍                            | 80/601 [00:13<01:27,  5.93it/s]\n",
            "Epoch 9:  17%|█████▎                          | 100/601 [00:17<01:27,  5.75it/s]\n",
            "Epoch 9:  20%|█▌      | 120/601 [00:18<01:13,  6.51it/s, loss=0.482, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  20317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|████████████████████████████████| 159/159 [00:31<00:00,  4.97it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.919377863407135, 'train_size': 66000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 5305  9800  7817 ... 15473  2570  8112]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "tcmalloc: large alloc 3160301568 bytes == 0x5632bc030000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c644d18 0x7fa95c6ec010 0x7fa95c6ec73c 0x7fa95c6ec85d 0x56303e47e2f8 0x7fa95c631ef7 0x56303e47bfd7 0x56303e47bde0 0x56303e4efac2 0x56303e4eab0e 0x56303e47d77a 0x56303e4efe50 0x56303e47d69a 0x56303e4ebc9e 0x56303e47d69a 0x56303e4eba45 0x56303e4eab0e 0x56303e4ea813 0x56303e5b4592 0x56303e5b490d 0x56303e5b47b6 0x56303e58c103 0x56303e58bdac 0x7fa95d85ebf7 0x56303e58bc8a\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            " New train set size  68000\n",
            "New unlabelled pool size  18317\n",
            "Epoch 9:   3%|█                                | 20/617 [00:01<00:35, 17.04it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   6%|██▏                              | 40/617 [00:05<01:21,  7.11it/s]\n",
            "Epoch 9:  10%|███▏                             | 60/617 [00:09<01:28,  6.29it/s]\n",
            "Epoch 9:  13%|████▎                            | 80/617 [00:13<01:30,  5.95it/s]\n",
            "Epoch 9:  16%|█████▏                          | 100/617 [00:17<01:29,  5.76it/s]\n",
            "Epoch 9:  19%|█▌      | 120/617 [00:18<01:16,  6.52it/s, loss=0.473, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  18317\n",
            "Query Sample size  2000\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 144/144 [00:28<00:00,  4.98it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.9261341691017151, 'train_size': 68000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[10178 16882 10468 ... 13570 10759 13467]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            " New train set size  70000\n",
            "New unlabelled pool size  16317\n",
            "Epoch 9:   3%|█                                | 20/632 [00:01<00:38, 15.99it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   6%|██                               | 40/632 [00:05<01:25,  6.91it/s]\n",
            "Epoch 9:   9%|███▏                             | 60/632 [00:09<01:32,  6.18it/s]\n",
            "Epoch 9:  13%|████▏                            | 80/632 [00:13<01:34,  5.86it/s]\n",
            "Epoch 9:  16%|█████                           | 100/632 [00:17<01:33,  5.69it/s]\n",
            "Epoch 9:  19%|█▌      | 120/632 [00:18<01:19,  6.45it/s, loss=0.464, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  16317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 128/128 [00:25<00:00,  4.95it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.9355886578559875, 'train_size': 70000.0078125}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[  515  6839  7199 ...  5543 13086  5494]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  72000\n",
            "New unlabelled pool size  14317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:   3%|█                                | 20/648 [00:01<00:38, 16.32it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   6%|██                               | 40/648 [00:05<01:28,  6.91it/s]\n",
            "Epoch 9:   9%|███                              | 60/648 [00:09<01:35,  6.18it/s]\n",
            "Epoch 9:  12%|████                             | 80/648 [00:13<01:36,  5.87it/s]\n",
            "Epoch 9:  15%|████▉                           | 100/648 [00:17<01:36,  5.69it/s]\n",
            "Epoch 9:  19%|█▍      | 120/648 [00:18<01:21,  6.45it/s, loss=0.463, v_num=2e60]\n",
            "                                                                                \u001b[ALOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Total Unlabelled Pool Size  14317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|████████████████████████████████| 112/112 [00:22<00:00,  4.92it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.9485227465629578, 'train_size': 72000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[11555 11571 11077 ...  9786  7489 13506]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  74000\n",
            "New unlabelled pool size  12317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:   3%|▉                                | 20/664 [00:01<00:38, 16.56it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   6%|█▉                               | 40/664 [00:05<01:29,  6.98it/s]\n",
            "Epoch 9:   9%|██▉                              | 60/664 [00:09<01:37,  6.20it/s]\n",
            "Epoch 9:  12%|███▉                             | 80/664 [00:13<01:39,  5.88it/s]\n",
            "Epoch 9:  15%|████▊                           | 100/664 [00:17<01:39,  5.70it/s]\n",
            "Epoch 9:  18%|█▍      | 120/664 [00:18<01:24,  6.45it/s, loss=0.462, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  12317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|██████████████████████████████████| 97/97 [00:19<00:00,  4.91it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.9435739517211914, 'train_size': 74000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 4056  9909  8891 ...  4163  4172 11971]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "tcmalloc: large alloc 3532103680 bytes == 0x5633da594000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c644d18 0x7fa95c6ec010 0x7fa95c6ec73c 0x7fa95c6ec85d 0x56303e47e2f8 0x7fa95c631ef7 0x56303e47bfd7 0x56303e47bde0 0x56303e4efac2 0x56303e4eab0e 0x56303e47d77a 0x56303e4efe50 0x56303e47d69a 0x56303e4ebc9e 0x56303e47d69a 0x56303e4eba45 0x56303e4eab0e 0x56303e4ea813 0x56303e5b4592 0x56303e5b490d 0x56303e5b47b6 0x56303e58c103 0x56303e58bdac 0x7fa95d85ebf7 0x56303e58bc8a\n",
            " New train set size  76000\n",
            "New unlabelled pool size  10317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:   3%|▉                                | 20/679 [00:01<00:40, 16.42it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   6%|█▉                               | 40/679 [00:05<01:31,  7.02it/s]\n",
            "Epoch 9:   9%|██▉                              | 60/679 [00:09<01:39,  6.23it/s]\n",
            "Epoch 9:  12%|███▉                             | 80/679 [00:13<01:41,  5.90it/s]\n",
            "Epoch 9:  15%|████▋                           | 100/679 [00:17<01:41,  5.72it/s]\n",
            "Epoch 9:  18%|█▍      | 120/679 [00:18<01:26,  6.47it/s, loss=0.464, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  10317\n",
            "Query Sample size  2000\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "Testing: 100%|██████████████████████████████████| 81/81 [00:16<00:00,  4.86it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.8807793259620667, 'train_size': 76000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[10287  6078  3862 ...  6171  9051  4451]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  78000\n",
            "New unlabelled pool size  8317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:   3%|▉                                | 20/695 [00:01<00:41, 16.26it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   6%|█▉                               | 40/695 [00:05<01:33,  6.97it/s]\n",
            "Epoch 9:   9%|██▊                              | 60/695 [00:09<01:42,  6.21it/s]\n",
            "Epoch 9:  12%|███▊                             | 80/695 [00:13<01:44,  5.89it/s]\n",
            "Epoch 9:  14%|████▌                           | 100/695 [00:17<01:44,  5.72it/s]\n",
            "Epoch 9:  17%|█▍      | 120/695 [00:18<01:28,  6.47it/s, loss=0.453, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  8317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|██████████████████████████████████| 65/65 [00:13<00:00,  4.80it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.9315859079360962, 'train_size': 78000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[1261 1227 3227 ... 3193 5367 1077]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  80000\n",
            "New unlabelled pool size  6317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:   3%|▉                                | 20/710 [00:01<00:41, 16.55it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   6%|█▊                               | 40/710 [00:05<01:35,  7.02it/s]\n",
            "Epoch 9:   8%|██▊                              | 60/710 [00:09<01:44,  6.24it/s]\n",
            "Epoch 9:  11%|███▋                             | 80/710 [00:13<01:46,  5.91it/s]\n",
            "Epoch 9:  14%|████▌                           | 100/710 [00:17<01:46,  5.73it/s]\n",
            "Epoch 9:  17%|█▎      | 120/710 [00:18<01:30,  6.49it/s, loss=0.448, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  6317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|██████████████████████████████████| 50/50 [00:10<00:00,  4.77it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.9488681554794312, 'train_size': 80000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[3319 3002 3460 ... 3427 2125 1590]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "Epoch 9:  17%|█▎      | 120/710 [00:34<02:47,  3.52it/s, loss=0.448, v_num=2e60] New train set size  82000\n",
            "New unlabelled pool size  4317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:   3%|▉                                | 20/726 [00:01<00:42, 16.64it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                        | 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   6%|█▊                               | 40/726 [00:05<01:37,  7.02it/s]\n",
            "Epoch 9:   8%|██▋                              | 60/726 [00:09<01:46,  6.24it/s]\n",
            "Epoch 9:  11%|███▋                             | 80/726 [00:13<01:49,  5.91it/s]\n",
            "Epoch 9:  14%|████▍                           | 100/726 [00:17<01:49,  5.73it/s]\n",
            "Epoch 9:  17%|█▎      | 120/726 [00:18<01:33,  6.48it/s, loss=0.438, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  4317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|██████████████████████████████████| 34/34 [00:07<00:00,  4.58it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.9557563066482544, 'train_size': 82000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[1460  440  943 ... 2460 2557 2662]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            " New train set size  84000\n",
            "New unlabelled pool size  2317\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 9:   3%|▉                                | 20/742 [00:01<00:44, 16.11it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 9:  17%|█▎      | 120/726 [00:33<02:49,  3.57it/s, loss=0.438, v_num=2e60]\n",
            "Epoch 9:   5%|█▊                               | 40/742 [00:05<01:42,  6.87it/s]\n",
            "Epoch 9:   8%|██▋                              | 60/742 [00:09<01:50,  6.16it/s]\n",
            "Epoch 9:  11%|███▌                             | 80/742 [00:13<01:53,  5.86it/s]\n",
            "Epoch 9:  13%|████▎                           | 100/742 [00:17<01:52,  5.69it/s]\n",
            "Epoch 9:  16%|█▎      | 120/742 [00:18<01:36,  6.43it/s, loss=0.431, v_num=2e60]\n",
            "                                                                                \u001b[ATotal Unlabelled Pool Size  2317\n",
            "Query Sample size  2000\n",
            "\n",
            "Resetting Predictions\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100%|██████████████████████████████████| 19/19 [00:04<00:00,  4.28it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.9581355452537537, 'train_size': 84000.0}\n",
            "--------------------------------------------------------------------------------\n",
            "Indices selected for labelling via method \"entropy\": \n",
            "-----------------\n",
            "\n",
            "[ 674  927    4 ... 1600  459  911]\n",
            "\n",
            "-----------------\n",
            "\n",
            "x-train_new size 2000\n",
            "len of sample ids 2000\n",
            "tcmalloc: large alloc 3996852224 bytes == 0x56332e99c000 @  0x7fa95ea741e7 0x7fa95c5f446e 0x7fa95c644c7b 0x7fa95c644d18 0x7fa95c6ec010 0x7fa95c6ec73c 0x7fa95c6ec85d 0x56303e47e2f8 0x7fa95c631ef7 0x56303e47bfd7 0x56303e47bde0 0x56303e4efac2 0x56303e4eab0e 0x56303e47d77a 0x56303e4efe50 0x56303e47d69a 0x56303e4ebc9e 0x56303e47d69a 0x56303e4eba45 0x56303e4eab0e 0x56303e4ea813 0x56303e5b4592 0x56303e5b490d 0x56303e5b47b6 0x56303e58c103 0x56303e58bdac 0x7fa95d85ebf7 0x56303e58bc8a\n",
            " New train set size  86000\n",
            "New unlabelled pool size  317\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 498\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/fsdl-active-learning2/wandb/run-20210505_125612-8lqj2e60/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/fsdl-active-learning2/wandb/run-20210505_125612-8lqj2e60/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                      train_loss 0.28895\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                       train_acc 0.90625\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                      train_size 84000.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                           epoch 9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                             trainer/global_step 7997\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                        _runtime 7607\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                      _timestamp 1620226979\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                           _step 116\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                        val_loss 1.08866\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                         val_acc 0.66255\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                        test_acc 0.95814\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_loss █▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▁▂▃▃▃▁▄▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train_acc ▁▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆█▇▆▆▆█▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_size ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch ▁▂▃▄▅▆▇█████████████████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇██████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇█████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇█████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              val_loss ▃▂▃▇▂▃▃▁▃▁▄▂▂▁▁▃▂▅▃▁▂▂▁▁▄▁▆▂▂▂▁▃▄▂▁▆▇█▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               val_acc ▃▅▄▁▆▆▆▇▄▇▃▅▅▇▇▇▇▇▇▇▆███▇█▇█▆▇▇▇▇██▇▆▇█▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_acc ▄▁▃▃▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▅▇▇▇████▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfsdl-active-learning_entropy\u001b[0m: \u001b[34mhttps://wandb.ai/ravindra/fsdl-active-learning/runs/8lqj2e60\u001b[0m\n",
            "Epoch 9: 100% 492/492 [37:17<00:00,  4.55s/it, loss=0.517, v_num=2e60]          \n",
            "Epoch 9:  21% 120/585 [07:59<30:59,  4.00s/it, loss=0.487, v_num=2e60]          \n",
            "Epoch 9: 100% 445/445 [52:57<00:00,  7.14s/it, loss=0.509, v_num=2e60]          \n",
            "Epoch 9: 100% 476/476 [42:37<00:00,  5.37s/it, loss=0.538, v_num=2e60]          \n",
            "Epoch 9:  20% 120/601 [07:03<28:15,  3.53s/it, loss=0.482, v_num=2e60]          \n",
            "Epoch 9: 100% 382/382 [1:12:20<00:00, 11.36s/it, loss=0.581, v_num=2e60]        \n",
            "Epoch 9: 100% 367/367 [1:16:54<00:00, 12.57s/it, loss=0.579, v_num=2e60]        \n",
            "Epoch 9: 100% 351/351 [1:21:21<00:00, 13.91s/it, loss=0.594, v_num=2e60]        \n",
            "Epoch 9: 100% 273/273 [1:41:59<00:00, 22.42s/it, loss=0.638, v_num=2e60]        \n",
            "Epoch 9: 100% 414/414 [1:02:51<00:00,  9.11s/it, loss=0.574, v_num=2e60]        \n",
            "Epoch 9: 100% 523/523 [26:18<00:00,  3.02s/it, loss=0.512, v_num=2e60]          \n",
            "Epoch 9:  18% 120/679 [03:04<14:20,  1.54s/it, loss=0.464, v_num=2e60]          \n",
            "Epoch 9:  19% 120/617 [06:09<25:29,  3.08s/it, loss=0.473, v_num=2e60]          \n",
            "Epoch 9:  19% 120/648 [04:30<19:51,  2.26s/it, loss=0.463, v_num=2e60]          \n",
            "Epoch 9:  19% 120/632 [05:18<22:39,  2.66s/it, loss=0.464, v_num=2e60]          \n",
            "Epoch 9:  21% 120/570 [08:59<33:44,  4.50s/it, loss=0.483, v_num=2e60]          \n",
            "Epoch 9:  17% 120/695 [02:26<11:40,  1.22s/it, loss=0.453, v_num=2e60]          \n",
            "Epoch 9:  17% 120/710 [01:50<09:05,  1.08it/s, loss=0.448, v_num=2e60]          \n",
            "Epoch 9:  18% 120/664 [03:46<17:05,  1.88s/it, loss=0.462, v_num=2e60]          \n",
            "Epoch 9:  17% 120/726 [01:00<05:05,  1.98it/s, loss=0.438, v_num=2e60]          \n",
            "Epoch 9: 100% 507/507 [31:51<00:00,  3.77s/it, loss=0.507, v_num=2e60]          \n",
            "Epoch 9: 100% 429/429 [57:58<00:00,  8.11s/it, loss=0.535, v_num=2e60]          \n",
            "Epoch 9: 100% 539/539 [20:38<00:00,  2.30s/it, loss=0.425, v_num=2e60]          \n",
            "Epoch 9: 100% 335/335 [1:25:42<00:00, 15.35s/it, loss=0.587, v_num=2e60]        \n",
            "Epoch 9: 100% 320/320 [1:29:56<00:00, 16.86s/it, loss=0.585, v_num=2e60]        \n",
            "Epoch 9: 100% 289/289 [1:38:04<00:00, 20.36s/it, loss=0.615, v_num=2e60]        \n",
            "Epoch 9: 100% 257/257 [1:45:47<00:00, 24.70s/it, loss=0.655, v_num=2e60]        \n",
            "Epoch 9: 100% 304/304 [1:34:04<00:00, 18.57s/it, loss=0.586, v_num=2e60]        \n",
            "Epoch 9: 100% 398/398 [1:07:40<00:00, 10.20s/it, loss=0.587, v_num=2e60]        \n",
            "Epoch 9: 100% 554/554 [14:52<00:00,  1.61s/it, loss=0.489, v_num=2e60]          \n",
            "Epoch 9: 100% 460/460 [47:51<00:00,  6.24s/it, loss=0.503, v_num=2e60]          \n",
            "Epoch 9:  16% 120/742 [00:31<02:40,  3.87it/s, loss=0.431, v_num=2e60]          \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}